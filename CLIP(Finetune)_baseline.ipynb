{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hmin27/2023_DL_Clip/blob/main/CLIP(Finetune)_baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rx2hKkBgzUkz"
      },
      "source": [
        "# CLIP Fine tuning\n",
        "- Food image classification\n",
        "- Baseline of Fine Tuned CLIP model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UU5QbpXrDWUl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 949
        },
        "outputId": "598d60a4-e098-4cf3-dc3f-02d282f73559"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ftfy\n",
            "  Downloading ftfy-6.1.3-py3-none-any.whl (53 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/53.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.4/53.4 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n",
            "Collecting wcwidth<0.3.0,>=0.2.12 (from ftfy)\n",
            "  Downloading wcwidth-0.2.12-py2.py3-none-any.whl (34 kB)\n",
            "Installing collected packages: wcwidth, ftfy\n",
            "  Attempting uninstall: wcwidth\n",
            "    Found existing installation: wcwidth 0.2.10\n",
            "    Uninstalling wcwidth-0.2.10:\n",
            "      Successfully uninstalled wcwidth-0.2.10\n",
            "Successfully installed ftfy-6.1.3 wcwidth-0.2.12\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "wcwidth"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/CLIP.git\n",
            "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-c05wvvu9\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-c05wvvu9\n",
            "  Resolved https://github.com/openai/CLIP.git to commit a1d071733d7111c9c014f024669f959182114e33\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (6.1.3)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (4.66.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (2.1.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (0.16.0+cu118)\n",
            "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy->clip==1.0) (0.2.12)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (2.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->clip==1.0) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision->clip==1.0) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->clip==1.0) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->clip==1.0) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->clip==1.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->clip==1.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->clip==1.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->clip==1.0) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->clip==1.0) (1.3.0)\n",
            "Building wheels for collected packages: clip\n",
            "  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369500 sha256=12199eece4fc64b78dd5f6ebf0d68071aaf664c0ba4e98b51db4b53093c1260a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-t1gn9wgn/wheels/da/2b/4c/d6691fa9597aac8bb85d2ac13b112deb897d5b50f5ad9a37e4\n",
            "Successfully built clip\n",
            "Installing collected packages: clip\n",
            "Successfully installed clip-1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install ftfy regex tqdm\n",
        "!pip install git+https://github.com/openai/CLIP.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wc7W2ooyDcLZ",
        "outputId": "4755ad8f-bf93-473c-d6c1-03727e230936"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import clip\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torchvision.datasets import ImageFolder\n",
        "from tqdm.notebook import tqdm\n",
        "import shutil\n",
        "\n",
        "%matplotlib inline\n",
        "BATCH_SIZE = 16\n",
        "EPOCH = 10\n",
        "LR = 1e-7\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p52DoKG6DmVA"
      },
      "source": [
        "# Prepare the Model and Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnmtrDVrE9xn",
        "outputId": "14522674-6efd-4bd0-d46c-cf5640f3d49a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X4faeiH7QkCV"
      },
      "outputs": [],
      "source": [
        "model, preprocess = clip.load(\"ViT-B/32\", device=device, jit=False)\n",
        "model = model.to(torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "79slliwKt9HA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbe05899-327a-4436-a0bc-3d90c37ca080"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['a photo of apple pie', 'a photo of apple pie', 'a photo of apple pie', 'a photo of apple pie', 'a photo of burger', 'a photo of burger', 'a photo of burger', 'a photo of burger', 'a photo of butter naan', 'a photo of butter naan', 'a photo of butter naan', 'a photo of butter naan', 'a photo of chai', 'a photo of chai', 'a photo of chai', 'a photo of chai', 'a photo of chapati', 'a photo of chapati', 'a photo of chapati', 'a photo of chapati', 'a photo of cheesecake', 'a photo of cheesecake', 'a photo of cheesecake', 'a photo of cheesecake', 'a photo of chicken curry', 'a photo of chicken curry', 'a photo of chicken curry', 'a photo of chicken curry', 'a photo of chole bhature', 'a photo of chole bhature', 'a photo of chole bhature', 'a photo of chole bhature', 'a photo of dal makhani', 'a photo of dal makhani', 'a photo of dal makhani', 'a photo of dal makhani', 'a photo of dhokla', 'a photo of dhokla', 'a photo of dhokla', 'a photo of dhokla', 'a photo of fried rice', 'a photo of fried rice', 'a photo of fried rice', 'a photo of fried rice', 'a photo of ice cream', 'a photo of ice cream', 'a photo of ice cream', 'a photo of ice cream', 'a photo of idli', 'a photo of idli', 'a photo of idli', 'a photo of idli', 'a photo of jalebi', 'a photo of jalebi', 'a photo of jalebi', 'a photo of jalebi', 'a photo of kaathi rolls', 'a photo of kaathi rolls', 'a photo of kaathi rolls', 'a photo of kaathi rolls', 'a photo of kadai paneer', 'a photo of kadai paneer', 'a photo of kadai paneer', 'a photo of kadai paneer', 'a photo of kulfi', 'a photo of kulfi', 'a photo of kulfi', 'a photo of kulfi', 'a photo of masala dosa', 'a photo of masala dosa', 'a photo of masala dosa', 'a photo of masala dosa', 'a photo of momos', 'a photo of momos', 'a photo of momos', 'a photo of momos', 'a photo of omelette', 'a photo of omelette', 'a photo of omelette', 'a photo of omelette', 'a photo of baked potato', 'a photo of baked potato', 'a photo of baked potato', 'a photo of baked potato', 'a photo of crispy chicken', 'a photo of crispy chicken', 'a photo of crispy chicken', 'a photo of crispy chicken', 'a photo of hot dog', 'a photo of hot dog', 'a photo of hot dog', 'a photo of hot dog', 'a photo of taco', 'a photo of taco', 'a photo of taco', 'a photo of taco', 'a photo of fries', 'a photo of fries', 'a photo of fries', 'a photo of fries', 'a photo of sandwich', 'a photo of sandwich', 'a photo of sandwich', 'a photo of sandwich', 'a photo of donut', 'a photo of donut', 'a photo of donut', 'a photo of donut', 'a photo of pakode', 'a photo of pakode', 'a photo of pakode', 'a photo of pakode', 'a photo of samosa', 'a photo of samosa', 'a photo of samosa', 'a photo of samosa', 'a photo of sushi', 'a photo of sushi', 'a photo of sushi', 'a photo of sushi', 'a photo of pizza', 'a photo of pizza', 'a photo of pizza', 'a photo of pizza', 'a photo of pav bhaji', 'a photo of pav bhaji', 'a photo of pav bhaji', 'a photo of pav bhaji', 'a photo of paani puri', 'a photo of paani puri', 'a photo of paani puri', 'a photo of paani puri']\n",
            "['apple_pie', 'burger', 'butter_naan', 'chai', 'chapati', 'cheesecake', 'chicken_curry', 'chole_bhature', 'dal_makhani', 'dhokla', 'fried_rice', 'ice_cream', 'idli', 'jalebi', 'kaathi_rolls', 'kadai_paneer', 'kulfi', 'masala_dosa', 'momos', 'omelette', 'baked potato', 'crispy chicken', 'hot dog', 'taco', 'fries', 'sandwich', 'donut', 'pakode', 'samosa', 'sushi', 'pizza', 'pav_bhaji', 'paani_puri']\n"
          ]
        }
      ],
      "source": [
        "# Creating image path, text list\n",
        "import pandas as pd\n",
        "\n",
        "data_folder = '/content/drive/MyDrive/Study/DL_CLIP/Food_fewshot/4_shot/train'\n",
        "\n",
        "image_paths = []\n",
        "text_descriptions = []\n",
        "class_folders = os.listdir(data_folder)\n",
        "class_names = []\n",
        "\n",
        "for class_folder in class_folders:\n",
        "    class_folder_path = os.path.join(data_folder, class_folder)\n",
        "    image_files = os.listdir(class_folder_path)\n",
        "\n",
        "    class_names.append(class_folder)\n",
        "    for image_file in image_files:\n",
        "        image_path = os.path.join(class_folder_path, image_file)\n",
        "        image_paths.append(image_path)\n",
        "\n",
        "        # Create text description using class label\n",
        "        text_description = f\"a photo of {class_folder.replace('_',' ')}\"\n",
        "        text_descriptions.append(text_description)\n",
        "\n",
        "\n",
        "\n",
        "print(text_descriptions)\n",
        "# len(text_descriptions)\n",
        "print(class_names)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Few-shot learning\n",
        "\n",
        "class FewshotDataset(Dataset):\n",
        "    def __init__(self, data_folder, preprocess):\n",
        "        self.data_folder = data_folder\n",
        "        self.preprocess = preprocess\n",
        "        self.image_paths = []\n",
        "        self.text_descriptions = []\n",
        "        self.labels = []\n",
        "\n",
        "        # image path list, text list\n",
        "        class_folders = os.listdir(data_folder)\n",
        "\n",
        "        for label, class_folder in enumerate(class_folders):\n",
        "            class_folder_path = os.path.join(data_folder, class_folder)\n",
        "            image_files = os.listdir(class_folder_path)\n",
        "\n",
        "            for image_file in image_files:\n",
        "                image_path = os.path.join(class_folder_path, image_file)\n",
        "                self.image_paths.append(image_path)\n",
        "\n",
        "                text_description = f\"a photo of {class_folder.replace('_',' ')}\"\n",
        "                self.text_descriptions.append(text_description)\n",
        "\n",
        "                self.labels.append(label)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = Image.open(self.image_paths[idx])\n",
        "        image = self.preprocess(image)\n",
        "        text = self.text_descriptions[idx]\n",
        "        label = self.labels[idx]\n",
        "        return image, text, label\n",
        "\n",
        "\n",
        "data_folder = '/content/drive/MyDrive/Study/DL_CLIP/Food_fewshot/4_shot'\n",
        "train_dataset = FewshotDataset(os.path.join(data_folder, 'train'), preprocess)\n",
        "val_dataset = FewshotDataset(os.path.join(data_folder, 'validation'), preprocess)\n",
        "test_dataset = FewshotDataset(os.path.join(data_folder, 'test'), preprocess)\n",
        "\n",
        "trainloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "valloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "testloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# len(train_dataset)  # 96\n",
        "# len(val_dataset)  # 28\n",
        "# len(test_dataset)  # 12"
      ],
      "metadata": {
        "id": "QAbI2GPpkUYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztG9Tqz-v1vs",
        "outputId": "04cae393-4723-405a-86f0-1d9068f50a86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image Path: torch.Size([3, 224, 224])\n",
            "Text Description: a photo of apple pie\n",
            "Label:  tensor([0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3])\n"
          ]
        }
      ],
      "source": [
        "from numpy.lib import shape_base\n",
        "for batch in valloader:\n",
        "    images, texts, labels = batch\n",
        "    # Print the first batch\n",
        "    print(\"Image Path:\", images[0].shape)\n",
        "    print(\"Text Description:\", texts[0])\n",
        "    print(\"Label: \", labels)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fL2zwBDdNvZw"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KlgzBPDONu3x"
      },
      "outputs": [],
      "source": [
        "def convert_models_to_fp32(model):\n",
        "    for p in model.parameters():\n",
        "        p.data = p.data.float()\n",
        "        p.grad.data = p.grad.data.float()\n",
        "\n",
        "loss_img = nn.CrossEntropyLoss()\n",
        "loss_txt = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
        "# scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, len(trainloader)*EPOCH)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.notebook import tqdm\n",
        "from sklearn.metrics import accuracy_score, top_k_accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "for epoch in range(EPOCH):\n",
        "    print(f\"Epoch: {epoch+1}\")\n",
        "\n",
        "    # Training loop\n",
        "    model.train()\n",
        "    train_total, train_correct, train_top1_correct, train_top3_correct = 0, 0, 0, 0\n",
        "    pbar = tqdm(trainloader, total=len(trainloader))\n",
        "    for batch in pbar:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        images, texts, _ = batch\n",
        "        texts = clip.tokenize(texts).to(device)\n",
        "        images = images.to(device)\n",
        "\n",
        "        logits_per_image, logits_per_text = model(images, texts)\n",
        "\n",
        "        # Compute loss\n",
        "        actual_batch_size = images.size(0)\n",
        "        ground_truth = torch.arange(actual_batch_size).to(device)\n",
        "        total_loss = (loss_img(logits_per_image, ground_truth) + loss_txt(logits_per_text, ground_truth)) / 2\n",
        "\n",
        "        # Compute train accuracy\n",
        "        train_correct += (logits_per_image.argmax(dim=1) == ground_truth).float().sum().item()\n",
        "\n",
        "        # Compute top-1 and top-5 accuracy\n",
        "        train_top1_correct += accuracy_score(ground_truth.cpu().detach().numpy(), logits_per_image.argmax(dim=1).cpu().detach().numpy()) * actual_batch_size\n",
        "        train_top3_correct += top_k_accuracy_score(ground_truth.cpu().detach().numpy(),logits_per_image.cpu().detach().numpy(), k=3) * actual_batch_size\n",
        "\n",
        "        train_total += actual_batch_size\n",
        "\n",
        "        total_loss.backward()\n",
        "\n",
        "        if device == \"cpu\":\n",
        "            optimizer.step()\n",
        "        else:\n",
        "            convert_models_to_fp32(model)\n",
        "            optimizer.step()\n",
        "            clip.model.convert_weights(model)\n",
        "\n",
        "        train_accuracy = 100 * train_correct / train_total\n",
        "        train_top1_accuracy = 100 * train_top1_correct / train_total\n",
        "        train_top3_accuracy = 100 * train_top3_correct / train_total\n",
        "        pbar.set_description(f\"Epoch {epoch+1}/{EPOCH}, Loss: {total_loss.item():.4f}, Train Top-1 Acc: {train_top1_accuracy:.2f}%, Train Top-3 Acc: {train_top3_accuracy:.2f}%\")\n",
        "\n",
        "    # Validation loop\n",
        "    model.eval()\n",
        "    val_total, val_correct_top1, val_correct_top3 = 0, 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in valloader:\n",
        "            images, texts, labels = batch\n",
        "            texts = clip.tokenize(texts).to(device)\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            logits_per_image, _ = model(images, texts)\n",
        "            print(\"Logits per Image:\", logits_per_image)\n",
        "\n",
        "            print(\"Predicted Labels:\", logits_per_image.argmax(dim=1))\n",
        "            print(\"Actual Labels:\", labels)\n",
        "\n",
        "            # Compute top-1 and top-3 accuracy\n",
        "            val_correct_top1 += (logits_per_image.argmax(dim=1) == labels).float().sum().item()\n",
        "            _, top3_predictions = logits_per_image.topk(3, dim=1)\n",
        "            val_correct_top3 += torch.any(top3_predictions == labels.view(-1, 1), dim=1).float().sum().item()\n",
        "\n",
        "            val_total += images.size(0)\n",
        "\n",
        "    # Compute and print validation accuracy\n",
        "    val_accuracy_top1 = 100 * val_correct_top1 / val_total\n",
        "    val_accuracy_top3 = 100 * val_correct_top3 / val_total\n",
        "\n",
        "    print(f\"Validation Top-1 Acc: {val_accuracy_top1:.2f}%, Validation Top-3 Acc: {val_accuracy_top3:.2f}%\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "d42cb5cb9db240658a05bd0f7cc84ef9",
            "7fe6bfb0df3945c9a4c87d12d13b1ca2",
            "e582a7ce0a14452088f99b180139a014",
            "aa894db688dd436a99a986b7ad69e04e",
            "8020eaaaf1fc47f9bd2fa971ed8d54a1",
            "5faafd87afac4a25b3df1620cc34f094",
            "802d021eb2c648ce9bbe05e652ad14a3",
            "9531d70d6b37474ab257a9835aa38914",
            "eee12b3b48214552a506212e804e1985",
            "66e19f51b16646aabe24f3c826c97832",
            "79786d3cb9e74b59806a8516643f295b",
            "e07fa7f840c7486991b871b3f8837462",
            "f03205fc071842e797db837589dbbbba",
            "94e76d4f30784e6e95ecb2ad28745ee1",
            "ea57c7d1ea1341a28257dafd1e2edd4b",
            "0bbdc83d51b748ae8fc839f23a7f06a5",
            "945976db55b2433da5d90add39be8603",
            "473a896388af472a915d88eecf920b31",
            "acaf88d4f79a462aaf0f287a760c80c5",
            "ba79dcbf105d40d3a8b06908fad0086e",
            "063540b3ebaa49f49b0efb9b0774b480",
            "1d5b4e079bcd4119b092d0119d9a9cf9",
            "440c1a051379499ca98cc8507837aa60",
            "0921f0f6e9ac4f08b6dd89d8f15247f6",
            "bf76884145b642bb828332098f21dde4",
            "75ed55bf793b47f3a7357f4af4eb267e",
            "9b8e8e46603c4477a2a88856bc3a977b",
            "e531639221a94d7ab280f37fc9941f14",
            "bed25b6985964f00a23631554b0a2f49",
            "a24dbb20e656407ba2e4041bd2afac9e",
            "f6144c9c5afc4ff792acb5875e0937c7",
            "d576918a57bc4d9d8ff66a94873ba1f1",
            "c956b908f90846a7815f3f2d4588b157"
          ]
        },
        "id": "w8xqpbMsLP8X",
        "outputId": "b2fb0267-46f7-4c7d-c680-11394240b0ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/9 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d42cb5cb9db240658a05bd0f7cc84ef9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logits per Image: tensor([[32.2812, 32.2812, 32.2812, 32.2812, 22.1250, 22.1250, 22.1250, 22.1250,\n",
            "         22.3125, 22.3125, 22.3125, 22.3125, 21.9219, 21.9219, 21.9219, 21.9219],\n",
            "        [31.7188, 31.7188, 31.7188, 31.7188, 21.7188, 21.7188, 21.7188, 21.7188,\n",
            "         21.1406, 21.1406, 21.1406, 21.1406, 19.4844, 19.4844, 19.4844, 19.4844],\n",
            "        [32.1562, 32.1562, 32.1562, 32.1562, 20.0000, 20.0000, 20.0000, 20.0000,\n",
            "         21.8281, 21.8281, 21.8281, 21.8281, 20.6719, 20.6719, 20.6719, 20.6719],\n",
            "        [29.2812, 29.2812, 29.2812, 29.2812, 17.7344, 17.7344, 17.7344, 17.7344,\n",
            "         18.2812, 18.2812, 18.2812, 18.2812, 18.0938, 18.0938, 18.0938, 18.0938],\n",
            "        [20.8750, 20.8750, 20.8750, 20.8750, 28.7500, 28.7500, 28.7500, 28.7500,\n",
            "         17.5625, 17.5625, 17.5625, 17.5625, 19.0625, 19.0625, 19.0625, 19.0625],\n",
            "        [18.5625, 18.5625, 18.5625, 18.5625, 26.7344, 26.7344, 26.7344, 26.7344,\n",
            "         16.9219, 16.9219, 16.9219, 16.9219, 18.5938, 18.5938, 18.5938, 18.5938],\n",
            "        [18.7031, 18.7031, 18.7031, 18.7031, 27.0469, 27.0469, 27.0469, 27.0469,\n",
            "         17.3438, 17.3438, 17.3438, 17.3438, 18.6250, 18.6250, 18.6250, 18.6250],\n",
            "        [18.8750, 18.8750, 18.8750, 18.8750, 27.9844, 27.9844, 27.9844, 27.9844,\n",
            "         16.7656, 16.7656, 16.7656, 16.7656, 19.8594, 19.8594, 19.8594, 19.8594],\n",
            "        [20.8125, 20.8125, 20.8125, 20.8125, 21.2188, 21.2188, 21.2188, 21.2188,\n",
            "         31.5156, 31.5156, 31.5156, 31.5156, 23.2656, 23.2656, 23.2656, 23.2656],\n",
            "        [18.1562, 18.1562, 18.1562, 18.1562, 19.0938, 19.0938, 19.0938, 19.0938,\n",
            "         32.0312, 32.0312, 32.0312, 32.0312, 23.0469, 23.0469, 23.0469, 23.0469],\n",
            "        [18.0000, 18.0000, 18.0000, 18.0000, 20.3281, 20.3281, 20.3281, 20.3281,\n",
            "         30.0312, 30.0312, 30.0312, 30.0312, 22.4375, 22.4375, 22.4375, 22.4375],\n",
            "        [20.8906, 20.8906, 20.8906, 20.8906, 19.9688, 19.9688, 19.9688, 19.9688,\n",
            "         31.8906, 31.8906, 31.8906, 31.8906, 21.3281, 21.3281, 21.3281, 21.3281],\n",
            "        [21.7188, 21.7188, 21.7188, 21.7188, 19.2969, 19.2969, 19.2969, 19.2969,\n",
            "         23.1875, 23.1875, 23.1875, 23.1875, 27.9062, 27.9062, 27.9062, 27.9062],\n",
            "        [19.5312, 19.5312, 19.5312, 19.5312, 17.3281, 17.3281, 17.3281, 17.3281,\n",
            "         18.7500, 18.7500, 18.7500, 18.7500, 24.1875, 24.1875, 24.1875, 24.1875],\n",
            "        [20.1250, 20.1250, 20.1250, 20.1250, 18.5000, 18.5000, 18.5000, 18.5000,\n",
            "         21.8125, 21.8125, 21.8125, 21.8125, 25.0469, 25.0469, 25.0469, 25.0469],\n",
            "        [22.2656, 22.2656, 22.2656, 22.2656, 20.8750, 20.8750, 20.8750, 20.8750,\n",
            "         22.9219, 22.9219, 22.9219, 22.9219, 28.9219, 28.9219, 28.9219, 28.9219]],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Predicted Labels: tensor([ 0,  0,  0,  0,  4,  4,  4,  4,  8,  8,  8,  8, 12, 12, 12, 12],\n",
            "       device='cuda:0')\n",
            "Actual Labels: tensor([0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3], device='cuda:0')\n",
            "Logits per Image: tensor([[35.9375, 35.9375, 35.9375, 35.9375, 23.0938, 23.0938, 23.0938, 23.0938,\n",
            "         21.3438, 21.3438, 21.3438, 21.3438, 28.3125, 28.3125, 28.3125, 28.3125],\n",
            "        [31.5625, 31.5625, 31.5625, 31.5625, 22.0156, 22.0156, 22.0156, 22.0156,\n",
            "         23.0469, 23.0469, 23.0469, 23.0469, 26.9688, 26.9688, 26.9688, 26.9688],\n",
            "        [36.4375, 36.4375, 36.4375, 36.4375, 21.9375, 21.9375, 21.9375, 21.9375,\n",
            "         25.6406, 25.6406, 25.6406, 25.6406, 29.2969, 29.2969, 29.2969, 29.2969],\n",
            "        [27.7969, 27.7969, 27.7969, 27.7969, 16.7969, 16.7969, 16.7969, 16.7969,\n",
            "         27.4844, 27.4844, 27.4844, 27.4844, 25.5000, 25.5000, 25.5000, 25.5000],\n",
            "        [16.7031, 16.7031, 16.7031, 16.7031, 23.3281, 23.3281, 23.3281, 23.3281,\n",
            "         15.7500, 15.7500, 15.7500, 15.7500, 16.0312, 16.0312, 16.0312, 16.0312],\n",
            "        [19.8281, 19.8281, 19.8281, 19.8281, 31.3594, 31.3594, 31.3594, 31.3594,\n",
            "         18.8594, 18.8594, 18.8594, 18.8594, 13.6250, 13.6250, 13.6250, 13.6250],\n",
            "        [20.3438, 20.3438, 20.3438, 20.3438, 31.4375, 31.4375, 31.4375, 31.4375,\n",
            "         19.4219, 19.4219, 19.4219, 19.4219, 15.1953, 15.1953, 15.1953, 15.1953],\n",
            "        [21.2969, 21.2969, 21.2969, 21.2969, 29.1094, 29.1094, 29.1094, 29.1094,\n",
            "         20.2500, 20.2500, 20.2500, 20.2500, 18.8125, 18.8125, 18.8125, 18.8125],\n",
            "        [22.8125, 22.8125, 22.8125, 22.8125, 17.2812, 17.2812, 17.2812, 17.2812,\n",
            "         30.0938, 30.0938, 30.0938, 30.0938, 19.2500, 19.2500, 19.2500, 19.2500],\n",
            "        [28.7656, 28.7656, 28.7656, 28.7656, 22.8594, 22.8594, 22.8594, 22.8594,\n",
            "         33.3125, 33.3125, 33.3125, 33.3125, 24.2344, 24.2344, 24.2344, 24.2344],\n",
            "        [24.5938, 24.5938, 24.5938, 24.5938, 19.4531, 19.4531, 19.4531, 19.4531,\n",
            "         30.0469, 30.0469, 30.0469, 30.0469, 24.6875, 24.6875, 24.6875, 24.6875],\n",
            "        [27.2812, 27.2812, 27.2812, 27.2812, 19.3125, 19.3125, 19.3125, 19.3125,\n",
            "         27.6562, 27.6562, 27.6562, 27.6562, 26.3125, 26.3125, 26.3125, 26.3125],\n",
            "        [27.9531, 27.9531, 27.9531, 27.9531, 17.6562, 17.6562, 17.6562, 17.6562,\n",
            "         24.8438, 24.8438, 24.8438, 24.8438, 31.0000, 31.0000, 31.0000, 31.0000],\n",
            "        [29.6406, 29.6406, 29.6406, 29.6406, 19.5469, 19.5469, 19.5469, 19.5469,\n",
            "         31.5000, 31.5000, 31.5000, 31.5000, 32.9062, 32.9062, 32.9062, 32.9062],\n",
            "        [25.1406, 25.1406, 25.1406, 25.1406, 18.1406, 18.1406, 18.1406, 18.1406,\n",
            "         25.6562, 25.6562, 25.6562, 25.6562, 32.5000, 32.5000, 32.5000, 32.5000],\n",
            "        [29.8281, 29.8281, 29.8281, 29.8281, 20.0156, 20.0156, 20.0156, 20.0156,\n",
            "         29.5469, 29.5469, 29.5469, 29.5469, 36.4688, 36.4688, 36.4688, 36.4688]],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Predicted Labels: tensor([ 0,  0,  0,  0,  4,  4,  4,  4,  8,  8,  8,  8, 12, 12, 12, 12],\n",
            "       device='cuda:0')\n",
            "Actual Labels: tensor([4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 7], device='cuda:0')\n",
            "Logits per Image: tensor([[32.0938, 32.0938, 32.0938, 32.0938, 23.2500, 23.2500, 23.2500, 23.2500,\n",
            "         20.9688, 20.9688, 20.9688, 20.9688, 16.0625, 16.0625, 16.0625, 16.0625],\n",
            "        [30.3906, 30.3906, 30.3906, 30.3906, 25.0938, 25.0938, 25.0938, 25.0938,\n",
            "         18.3750, 18.3750, 18.3750, 18.3750, 16.0938, 16.0938, 16.0938, 16.0938],\n",
            "        [32.8438, 32.8438, 32.8438, 32.8438, 15.9922, 15.9922, 15.9922, 15.9922,\n",
            "         16.9688, 16.9688, 16.9688, 16.9688, 17.5156, 17.5156, 17.5156, 17.5156],\n",
            "        [32.7500, 32.7500, 32.7500, 32.7500, 22.0312, 22.0312, 22.0312, 22.0312,\n",
            "         17.6875, 17.6875, 17.6875, 17.6875, 15.3984, 15.3984, 15.3984, 15.3984],\n",
            "        [24.1250, 24.1250, 24.1250, 24.1250, 34.1562, 34.1562, 34.1562, 34.1562,\n",
            "         20.2656, 20.2656, 20.2656, 20.2656, 18.5781, 18.5781, 18.5781, 18.5781],\n",
            "        [20.5625, 20.5625, 20.5625, 20.5625, 33.8438, 33.8438, 33.8438, 33.8438,\n",
            "         23.5625, 23.5625, 23.5625, 23.5625, 20.9375, 20.9375, 20.9375, 20.9375],\n",
            "        [22.7969, 22.7969, 22.7969, 22.7969, 33.7500, 33.7500, 33.7500, 33.7500,\n",
            "         17.0000, 17.0000, 17.0000, 17.0000, 19.1719, 19.1719, 19.1719, 19.1719],\n",
            "        [20.4062, 20.4062, 20.4062, 20.4062, 35.4375, 35.4375, 35.4375, 35.4375,\n",
            "         19.6719, 19.6719, 19.6719, 19.6719, 17.1719, 17.1719, 17.1719, 17.1719],\n",
            "        [22.9688, 22.9688, 22.9688, 22.9688, 21.0938, 21.0938, 21.0938, 21.0938,\n",
            "         27.1406, 27.1406, 27.1406, 27.1406, 19.1406, 19.1406, 19.1406, 19.1406],\n",
            "        [19.1875, 19.1875, 19.1875, 19.1875, 23.3125, 23.3125, 23.3125, 23.3125,\n",
            "         31.8594, 31.8594, 31.8594, 31.8594, 15.4375, 15.4375, 15.4375, 15.4375],\n",
            "        [17.6094, 17.6094, 17.6094, 17.6094, 18.0938, 18.0938, 18.0938, 18.0938,\n",
            "         31.1094, 31.1094, 31.1094, 31.1094, 14.7578, 14.7578, 14.7578, 14.7578],\n",
            "        [18.3281, 18.3281, 18.3281, 18.3281, 22.2344, 22.2344, 22.2344, 22.2344,\n",
            "         32.5312, 32.5312, 32.5312, 32.5312, 14.4062, 14.4062, 14.4062, 14.4062],\n",
            "        [16.9062, 16.9062, 16.9062, 16.9062, 16.1562, 16.1562, 16.1562, 16.1562,\n",
            "         18.4062, 18.4062, 18.4062, 18.4062, 27.9219, 27.9219, 27.9219, 27.9219],\n",
            "        [20.4062, 20.4062, 20.4062, 20.4062, 19.9375, 19.9375, 19.9375, 19.9375,\n",
            "         17.5156, 17.5156, 17.5156, 17.5156, 28.5781, 28.5781, 28.5781, 28.5781],\n",
            "        [17.4375, 17.4375, 17.4375, 17.4375, 15.2734, 15.2734, 15.2734, 15.2734,\n",
            "         19.2031, 19.2031, 19.2031, 19.2031, 26.3906, 26.3906, 26.3906, 26.3906],\n",
            "        [17.6719, 17.6719, 17.6719, 17.6719, 20.8594, 20.8594, 20.8594, 20.8594,\n",
            "         21.3438, 21.3438, 21.3438, 21.3438, 27.6719, 27.6719, 27.6719, 27.6719]],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Predicted Labels: tensor([ 0,  0,  0,  0,  4,  4,  4,  4,  8,  8,  8,  8, 12, 12, 12, 12],\n",
            "       device='cuda:0')\n",
            "Actual Labels: tensor([ 8,  8,  8,  8,  9,  9,  9,  9, 10, 10, 10, 10, 11, 11, 11, 11],\n",
            "       device='cuda:0')\n",
            "Logits per Image: tensor([[35.4375, 35.4375, 35.4375, 35.4375, 23.2188, 23.2188, 23.2188, 23.2188,\n",
            "         29.7188, 29.7188, 29.7188, 29.7188, 24.4844, 24.4844, 24.4844, 24.4844],\n",
            "        [35.3438, 35.3438, 35.3438, 35.3438, 21.3438, 21.3438, 21.3438, 21.3438,\n",
            "         30.8750, 30.8750, 30.8750, 30.8750, 23.8281, 23.8281, 23.8281, 23.8281],\n",
            "        [32.4375, 32.4375, 32.4375, 32.4375, 24.2031, 24.2031, 24.2031, 24.2031,\n",
            "         29.4375, 29.4375, 29.4375, 29.4375, 25.7344, 25.7344, 25.7344, 25.7344],\n",
            "        [33.2812, 33.2812, 33.2812, 33.2812, 21.7188, 21.7188, 21.7188, 21.7188,\n",
            "         28.3594, 28.3594, 28.3594, 28.3594, 25.4062, 25.4062, 25.4062, 25.4062],\n",
            "        [23.5781, 23.5781, 23.5781, 23.5781, 37.7188, 37.7188, 37.7188, 37.7188,\n",
            "         25.7812, 25.7812, 25.7812, 25.7812, 20.6094, 20.6094, 20.6094, 20.6094],\n",
            "        [21.9375, 21.9375, 21.9375, 21.9375, 32.3750, 32.3750, 32.3750, 32.3750,\n",
            "         25.8750, 25.8750, 25.8750, 25.8750, 21.5781, 21.5781, 21.5781, 21.5781],\n",
            "        [27.7344, 27.7344, 27.7344, 27.7344, 28.9219, 28.9219, 28.9219, 28.9219,\n",
            "         27.6562, 27.6562, 27.6562, 27.6562, 24.8594, 24.8594, 24.8594, 24.8594],\n",
            "        [22.6094, 22.6094, 22.6094, 22.6094, 37.0312, 37.0312, 37.0312, 37.0312,\n",
            "         26.9688, 26.9688, 26.9688, 26.9688, 21.2031, 21.2031, 21.2031, 21.2031],\n",
            "        [21.6406, 21.6406, 21.6406, 21.6406, 22.2969, 22.2969, 22.2969, 22.2969,\n",
            "         31.5625, 31.5625, 31.5625, 31.5625, 21.5156, 21.5156, 21.5156, 21.5156],\n",
            "        [22.5938, 22.5938, 22.5938, 22.5938, 21.0938, 21.0938, 21.0938, 21.0938,\n",
            "         25.4844, 25.4844, 25.4844, 25.4844, 21.2969, 21.2969, 21.2969, 21.2969],\n",
            "        [24.3906, 24.3906, 24.3906, 24.3906, 24.9531, 24.9531, 24.9531, 24.9531,\n",
            "         30.9219, 30.9219, 30.9219, 30.9219, 25.9844, 25.9844, 25.9844, 25.9844],\n",
            "        [25.2656, 25.2656, 25.2656, 25.2656, 21.6406, 21.6406, 21.6406, 21.6406,\n",
            "         29.9062, 29.9062, 29.9062, 29.9062, 23.7969, 23.7969, 23.7969, 23.7969],\n",
            "        [27.9688, 27.9688, 27.9688, 27.9688, 21.8281, 21.8281, 21.8281, 21.8281,\n",
            "         23.1406, 23.1406, 23.1406, 23.1406, 31.8125, 31.8125, 31.8125, 31.8125],\n",
            "        [28.7188, 28.7188, 28.7188, 28.7188, 24.0625, 24.0625, 24.0625, 24.0625,\n",
            "         25.1562, 25.1562, 25.1562, 25.1562, 34.0000, 34.0000, 34.0000, 34.0000],\n",
            "        [26.4062, 26.4062, 26.4062, 26.4062, 26.5156, 26.5156, 26.5156, 26.5156,\n",
            "         24.0625, 24.0625, 24.0625, 24.0625, 27.4219, 27.4219, 27.4219, 27.4219],\n",
            "        [27.5469, 27.5469, 27.5469, 27.5469, 23.5625, 23.5625, 23.5625, 23.5625,\n",
            "         26.0938, 26.0938, 26.0938, 26.0938, 31.8906, 31.8906, 31.8906, 31.8906]],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Predicted Labels: tensor([ 0,  0,  0,  0,  4,  4,  4,  4,  8,  8,  8,  8, 12, 12, 12, 12],\n",
            "       device='cuda:0')\n",
            "Actual Labels: tensor([12, 12, 12, 12, 13, 13, 13, 13, 14, 14, 14, 14, 15, 15, 15, 15],\n",
            "       device='cuda:0')\n",
            "Logits per Image: tensor([[31.0156, 31.0156, 31.0156, 31.0156, 25.2500, 25.2500, 25.2500, 25.2500,\n",
            "         22.7188, 22.7188, 22.7188, 22.7188, 24.7500, 24.7500, 24.7500, 24.7500],\n",
            "        [26.0625, 26.0625, 26.0625, 26.0625, 20.4062, 20.4062, 20.4062, 20.4062,\n",
            "         19.9062, 19.9062, 19.9062, 19.9062, 20.5469, 20.5469, 20.5469, 20.5469],\n",
            "        [32.2500, 32.2500, 32.2500, 32.2500, 23.1094, 23.1094, 23.1094, 23.1094,\n",
            "         26.1719, 26.1719, 26.1719, 26.1719, 20.7031, 20.7031, 20.7031, 20.7031],\n",
            "        [28.7969, 28.7969, 28.7969, 28.7969, 27.2031, 27.2031, 27.2031, 27.2031,\n",
            "         25.3594, 25.3594, 25.3594, 25.3594, 18.6094, 18.6094, 18.6094, 18.6094],\n",
            "        [25.0469, 25.0469, 25.0469, 25.0469, 32.2188, 32.2188, 32.2188, 32.2188,\n",
            "         25.5312, 25.5312, 25.5312, 25.5312, 24.3281, 24.3281, 24.3281, 24.3281],\n",
            "        [28.6719, 28.6719, 28.6719, 28.6719, 37.5625, 37.5625, 37.5625, 37.5625,\n",
            "         25.8438, 25.8438, 25.8438, 25.8438, 23.1094, 23.1094, 23.1094, 23.1094],\n",
            "        [22.7188, 22.7188, 22.7188, 22.7188, 27.7188, 27.7188, 27.7188, 27.7188,\n",
            "         21.9219, 21.9219, 21.9219, 21.9219, 18.1250, 18.1250, 18.1250, 18.1250],\n",
            "        [25.4219, 25.4219, 25.4219, 25.4219, 29.7500, 29.7500, 29.7500, 29.7500,\n",
            "         22.6875, 22.6875, 22.6875, 22.6875, 25.9844, 25.9844, 25.9844, 25.9844],\n",
            "        [25.0469, 25.0469, 25.0469, 25.0469, 19.8750, 19.8750, 19.8750, 19.8750,\n",
            "         34.5312, 34.5312, 34.5312, 34.5312, 22.4219, 22.4219, 22.4219, 22.4219],\n",
            "        [23.2031, 23.2031, 23.2031, 23.2031, 19.2188, 19.2188, 19.2188, 19.2188,\n",
            "         33.2812, 33.2812, 33.2812, 33.2812, 20.2969, 20.2969, 20.2969, 20.2969],\n",
            "        [22.9062, 22.9062, 22.9062, 22.9062, 18.3125, 18.3125, 18.3125, 18.3125,\n",
            "         30.5469, 30.5469, 30.5469, 30.5469, 19.8594, 19.8594, 19.8594, 19.8594],\n",
            "        [22.0469, 22.0469, 22.0469, 22.0469, 18.0469, 18.0469, 18.0469, 18.0469,\n",
            "         33.9688, 33.9688, 33.9688, 33.9688, 18.8281, 18.8281, 18.8281, 18.8281],\n",
            "        [21.2344, 21.2344, 21.2344, 21.2344, 21.5781, 21.5781, 21.5781, 21.5781,\n",
            "         18.5938, 18.5938, 18.5938, 18.5938, 28.8594, 28.8594, 28.8594, 28.8594],\n",
            "        [20.4531, 20.4531, 20.4531, 20.4531, 23.2188, 23.2188, 23.2188, 23.2188,\n",
            "         16.2812, 16.2812, 16.2812, 16.2812, 27.0000, 27.0000, 27.0000, 27.0000],\n",
            "        [21.9062, 21.9062, 21.9062, 21.9062, 22.3438, 22.3438, 22.3438, 22.3438,\n",
            "         17.5312, 17.5312, 17.5312, 17.5312, 28.3281, 28.3281, 28.3281, 28.3281],\n",
            "        [21.1094, 21.1094, 21.1094, 21.1094, 24.4062, 24.4062, 24.4062, 24.4062,\n",
            "         18.3750, 18.3750, 18.3750, 18.3750, 29.3750, 29.3750, 29.3750, 29.3750]],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Predicted Labels: tensor([ 0,  0,  0,  0,  4,  4,  4,  4,  8,  8,  8,  8, 12, 12, 12, 12],\n",
            "       device='cuda:0')\n",
            "Actual Labels: tensor([16, 16, 16, 16, 17, 17, 17, 17, 18, 18, 18, 18, 19, 19, 19, 19],\n",
            "       device='cuda:0')\n",
            "Logits per Image: tensor([[28.3125, 28.3125, 28.3125, 28.3125, 22.1250, 22.1250, 22.1250, 22.1250,\n",
            "         18.8594, 18.8594, 18.8594, 18.8594, 20.0781, 20.0781, 20.0781, 20.0781],\n",
            "        [29.2500, 29.2500, 29.2500, 29.2500, 23.5000, 23.5000, 23.5000, 23.5000,\n",
            "         24.0312, 24.0312, 24.0312, 24.0312, 22.5625, 22.5625, 22.5625, 22.5625],\n",
            "        [26.4219, 26.4219, 26.4219, 26.4219, 19.4531, 19.4531, 19.4531, 19.4531,\n",
            "         19.9531, 19.9531, 19.9531, 19.9531, 21.6875, 21.6875, 21.6875, 21.6875],\n",
            "        [27.7812, 27.7812, 27.7812, 27.7812, 26.0000, 26.0000, 26.0000, 26.0000,\n",
            "         22.7969, 22.7969, 22.7969, 22.7969, 20.9531, 20.9531, 20.9531, 20.9531],\n",
            "        [22.4688, 22.4688, 22.4688, 22.4688, 28.7188, 28.7188, 28.7188, 28.7188,\n",
            "         20.9219, 20.9219, 20.9219, 20.9219, 20.9062, 20.9062, 20.9062, 20.9062],\n",
            "        [17.8438, 17.8438, 17.8438, 17.8438, 30.5625, 30.5625, 30.5625, 30.5625,\n",
            "         18.7344, 18.7344, 18.7344, 18.7344, 20.2344, 20.2344, 20.2344, 20.2344],\n",
            "        [18.4219, 18.4219, 18.4219, 18.4219, 28.9375, 28.9375, 28.9375, 28.9375,\n",
            "         21.7969, 21.7969, 21.7969, 21.7969, 21.2969, 21.2969, 21.2969, 21.2969],\n",
            "        [19.8438, 19.8438, 19.8438, 19.8438, 27.0938, 27.0938, 27.0938, 27.0938,\n",
            "         19.0938, 19.0938, 19.0938, 19.0938, 20.7188, 20.7188, 20.7188, 20.7188],\n",
            "        [21.7031, 21.7031, 21.7031, 21.7031, 21.1875, 21.1875, 21.1875, 21.1875,\n",
            "         27.6562, 27.6562, 27.6562, 27.6562, 21.3125, 21.3125, 21.3125, 21.3125],\n",
            "        [25.8906, 25.8906, 25.8906, 25.8906, 22.8281, 22.8281, 22.8281, 22.8281,\n",
            "         32.5312, 32.5312, 32.5312, 32.5312, 23.7812, 23.7812, 23.7812, 23.7812],\n",
            "        [23.7500, 23.7500, 23.7500, 23.7500, 20.1250, 20.1250, 20.1250, 20.1250,\n",
            "         29.9219, 29.9219, 29.9219, 29.9219, 22.5938, 22.5938, 22.5938, 22.5938],\n",
            "        [21.1250, 21.1250, 21.1250, 21.1250, 19.3750, 19.3750, 19.3750, 19.3750,\n",
            "         29.1250, 29.1250, 29.1250, 29.1250, 21.8281, 21.8281, 21.8281, 21.8281],\n",
            "        [21.3125, 21.3125, 21.3125, 21.3125, 21.7188, 21.7188, 21.7188, 21.7188,\n",
            "         21.2969, 21.2969, 21.2969, 21.2969, 26.1562, 26.1562, 26.1562, 26.1562],\n",
            "        [20.2656, 20.2656, 20.2656, 20.2656, 19.5156, 19.5156, 19.5156, 19.5156,\n",
            "         20.1562, 20.1562, 20.1562, 20.1562, 24.5312, 24.5312, 24.5312, 24.5312],\n",
            "        [24.7188, 24.7188, 24.7188, 24.7188, 22.0781, 22.0781, 22.0781, 22.0781,\n",
            "         21.6250, 21.6250, 21.6250, 21.6250, 26.4688, 26.4688, 26.4688, 26.4688],\n",
            "        [23.5469, 23.5469, 23.5469, 23.5469, 22.2969, 22.2969, 22.2969, 22.2969,\n",
            "         24.9062, 24.9062, 24.9062, 24.9062, 28.9219, 28.9219, 28.9219, 28.9219]],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Predicted Labels: tensor([ 0,  0,  0,  0,  4,  4,  4,  4,  8,  8,  8,  8, 12, 12, 12, 12],\n",
            "       device='cuda:0')\n",
            "Actual Labels: tensor([20, 20, 20, 20, 21, 21, 21, 21, 22, 22, 22, 22, 23, 23, 23, 23],\n",
            "       device='cuda:0')\n",
            "Logits per Image: tensor([[32.0938, 32.0938, 32.0938, 32.0938, 24.2656, 24.2656, 24.2656, 24.2656,\n",
            "         19.2969, 19.2969, 19.2969, 19.2969, 28.4844, 28.4844, 28.4844, 28.4844],\n",
            "        [33.4062, 33.4062, 33.4062, 33.4062, 23.5312, 23.5312, 23.5312, 23.5312,\n",
            "         20.3125, 20.3125, 20.3125, 20.3125, 26.6250, 26.6250, 26.6250, 26.6250],\n",
            "        [33.9375, 33.9375, 33.9375, 33.9375, 24.0469, 24.0469, 24.0469, 24.0469,\n",
            "         21.2344, 21.2344, 21.2344, 21.2344, 26.1875, 26.1875, 26.1875, 26.1875],\n",
            "        [30.3594, 30.3594, 30.3594, 30.3594, 23.1094, 23.1094, 23.1094, 23.1094,\n",
            "         21.8906, 21.8906, 21.8906, 21.8906, 26.7188, 26.7188, 26.7188, 26.7188],\n",
            "        [20.3906, 20.3906, 20.3906, 20.3906, 29.4062, 29.4062, 29.4062, 29.4062,\n",
            "         19.7812, 19.7812, 19.7812, 19.7812, 19.0156, 19.0156, 19.0156, 19.0156],\n",
            "        [19.2812, 19.2812, 19.2812, 19.2812, 28.6406, 28.6406, 28.6406, 28.6406,\n",
            "         19.8906, 19.8906, 19.8906, 19.8906, 17.3125, 17.3125, 17.3125, 17.3125],\n",
            "        [20.9844, 20.9844, 20.9844, 20.9844, 26.2344, 26.2344, 26.2344, 26.2344,\n",
            "         22.3281, 22.3281, 22.3281, 22.3281, 25.4375, 25.4375, 25.4375, 25.4375],\n",
            "        [19.3125, 19.3125, 19.3125, 19.3125, 29.5625, 29.5625, 29.5625, 29.5625,\n",
            "         20.6875, 20.6875, 20.6875, 20.6875, 19.6875, 19.6875, 19.6875, 19.6875],\n",
            "        [18.6406, 18.6406, 18.6406, 18.6406, 19.8281, 19.8281, 19.8281, 19.8281,\n",
            "         27.6094, 27.6094, 27.6094, 27.6094, 17.5781, 17.5781, 17.5781, 17.5781],\n",
            "        [15.5391, 15.5391, 15.5391, 15.5391, 18.6562, 18.6562, 18.6562, 18.6562,\n",
            "         27.9062, 27.9062, 27.9062, 27.9062, 16.0000, 16.0000, 16.0000, 16.0000],\n",
            "        [23.8750, 23.8750, 23.8750, 23.8750, 22.9531, 22.9531, 22.9531, 22.9531,\n",
            "         31.4844, 31.4844, 31.4844, 31.4844, 23.9375, 23.9375, 23.9375, 23.9375],\n",
            "        [17.7188, 17.7188, 17.7188, 17.7188, 21.9844, 21.9844, 21.9844, 21.9844,\n",
            "         29.1562, 29.1562, 29.1562, 29.1562, 17.7969, 17.7969, 17.7969, 17.7969],\n",
            "        [21.8438, 21.8438, 21.8438, 21.8438, 18.6406, 18.6406, 18.6406, 18.6406,\n",
            "         21.0625, 21.0625, 21.0625, 21.0625, 28.8281, 28.8281, 28.8281, 28.8281],\n",
            "        [21.2500, 21.2500, 21.2500, 21.2500, 21.5469, 21.5469, 21.5469, 21.5469,\n",
            "         19.8125, 19.8125, 19.8125, 19.8125, 26.1719, 26.1719, 26.1719, 26.1719],\n",
            "        [24.7969, 24.7969, 24.7969, 24.7969, 20.3594, 20.3594, 20.3594, 20.3594,\n",
            "         18.3750, 18.3750, 18.3750, 18.3750, 30.2188, 30.2188, 30.2188, 30.2188],\n",
            "        [15.3516, 15.3516, 15.3516, 15.3516, 14.1953, 14.1953, 14.1953, 14.1953,\n",
            "         12.5156, 12.5156, 12.5156, 12.5156, 30.5312, 30.5312, 30.5312, 30.5312]],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Predicted Labels: tensor([ 0,  0,  0,  0,  4,  4,  4,  4,  8,  8,  8,  8, 12, 12, 12, 12],\n",
            "       device='cuda:0')\n",
            "Actual Labels: tensor([24, 24, 24, 24, 25, 25, 25, 25, 26, 26, 26, 26, 27, 27, 27, 27],\n",
            "       device='cuda:0')\n",
            "Logits per Image: tensor([[33.1562, 33.1562, 33.1562, 33.1562, 20.9062, 20.9062, 20.9062, 20.9062,\n",
            "         22.2031, 22.2031, 22.2031, 22.2031, 23.2500, 23.2500, 23.2500, 23.2500],\n",
            "        [32.3125, 32.3125, 32.3125, 32.3125, 23.0625, 23.0625, 23.0625, 23.0625,\n",
            "         21.9062, 21.9062, 21.9062, 21.9062, 22.2812, 22.2812, 22.2812, 22.2812],\n",
            "        [28.9531, 28.9531, 28.9531, 28.9531, 21.2344, 21.2344, 21.2344, 21.2344,\n",
            "         21.0000, 21.0000, 21.0000, 21.0000, 19.6250, 19.6250, 19.6250, 19.6250],\n",
            "        [29.5625, 29.5625, 29.5625, 29.5625, 18.1250, 18.1250, 18.1250, 18.1250,\n",
            "         17.7500, 17.7500, 17.7500, 17.7500, 20.9375, 20.9375, 20.9375, 20.9375],\n",
            "        [23.2031, 23.2031, 23.2031, 23.2031, 27.7656, 27.7656, 27.7656, 27.7656,\n",
            "         19.9375, 19.9375, 19.9375, 19.9375, 19.4844, 19.4844, 19.4844, 19.4844],\n",
            "        [21.8438, 21.8438, 21.8438, 21.8438, 29.0781, 29.0781, 29.0781, 29.0781,\n",
            "         18.8594, 18.8594, 18.8594, 18.8594, 15.6562, 15.6562, 15.6562, 15.6562],\n",
            "        [22.9062, 22.9062, 22.9062, 22.9062, 31.5156, 31.5156, 31.5156, 31.5156,\n",
            "         19.3906, 19.3906, 19.3906, 19.3906, 19.3281, 19.3281, 19.3281, 19.3281],\n",
            "        [22.7031, 22.7031, 22.7031, 22.7031, 31.6094, 31.6094, 31.6094, 31.6094,\n",
            "         19.8281, 19.8281, 19.8281, 19.8281, 17.6094, 17.6094, 17.6094, 17.6094],\n",
            "        [23.0469, 23.0469, 23.0469, 23.0469, 20.1250, 20.1250, 20.1250, 20.1250,\n",
            "         28.0625, 28.0625, 28.0625, 28.0625, 19.7344, 19.7344, 19.7344, 19.7344],\n",
            "        [22.2188, 22.2188, 22.2188, 22.2188, 18.5781, 18.5781, 18.5781, 18.5781,\n",
            "         27.7188, 27.7188, 27.7188, 27.7188, 20.5938, 20.5938, 20.5938, 20.5938],\n",
            "        [19.6406, 19.6406, 19.6406, 19.6406, 19.4844, 19.4844, 19.4844, 19.4844,\n",
            "         28.9844, 28.9844, 28.9844, 28.9844, 17.7188, 17.7188, 17.7188, 17.7188],\n",
            "        [17.5781, 17.5781, 17.5781, 17.5781, 19.1094, 19.1094, 19.1094, 19.1094,\n",
            "         28.4688, 28.4688, 28.4688, 28.4688, 16.8281, 16.8281, 16.8281, 16.8281],\n",
            "        [22.5781, 22.5781, 22.5781, 22.5781, 21.7812, 21.7812, 21.7812, 21.7812,\n",
            "         19.6562, 19.6562, 19.6562, 19.6562, 28.4688, 28.4688, 28.4688, 28.4688],\n",
            "        [25.0938, 25.0938, 25.0938, 25.0938, 20.6250, 20.6250, 20.6250, 20.6250,\n",
            "         21.4062, 21.4062, 21.4062, 21.4062, 37.2500, 37.2500, 37.2500, 37.2500],\n",
            "        [26.8906, 26.8906, 26.8906, 26.8906, 21.3594, 21.3594, 21.3594, 21.3594,\n",
            "         22.2188, 22.2188, 22.2188, 22.2188, 30.0469, 30.0469, 30.0469, 30.0469],\n",
            "        [27.3906, 27.3906, 27.3906, 27.3906, 17.5781, 17.5781, 17.5781, 17.5781,\n",
            "         19.6875, 19.6875, 19.6875, 19.6875, 35.1250, 35.1250, 35.1250, 35.1250]],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Predicted Labels: tensor([ 0,  0,  0,  0,  4,  4,  4,  4,  8,  8,  8,  8, 12, 12, 12, 12],\n",
            "       device='cuda:0')\n",
            "Actual Labels: tensor([28, 28, 28, 28, 29, 29, 29, 29, 30, 30, 30, 30, 31, 31, 31, 31],\n",
            "       device='cuda:0')\n",
            "Logits per Image: tensor([[32.0625, 32.0625, 32.0625, 32.0625],\n",
            "        [32.5938, 32.5938, 32.5938, 32.5938],\n",
            "        [34.0938, 34.0938, 34.0938, 34.0938],\n",
            "        [30.7188, 30.7188, 30.7188, 30.7188]], device='cuda:0',\n",
            "       dtype=torch.float16)\n",
            "Predicted Labels: tensor([0, 0, 0, 0], device='cuda:0')\n",
            "Actual Labels: tensor([32, 32, 32, 32], device='cuda:0')\n",
            "Validation Top-1 Acc: 3.03%, Validation Top-3 Acc: 9.09%\n",
            "Epoch: 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/9 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e07fa7f840c7486991b871b3f8837462"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logits per Image: tensor([[32.2812, 32.2812, 32.2812, 32.2812, 22.1094, 22.1094, 22.1094, 22.1094,\n",
            "         22.3281, 22.3281, 22.3281, 22.3281, 21.9219, 21.9219, 21.9219, 21.9219],\n",
            "        [31.7031, 31.7031, 31.7031, 31.7031, 21.7031, 21.7031, 21.7031, 21.7031,\n",
            "         21.1406, 21.1406, 21.1406, 21.1406, 19.4844, 19.4844, 19.4844, 19.4844],\n",
            "        [32.1562, 32.1562, 32.1562, 32.1562, 19.9844, 19.9844, 19.9844, 19.9844,\n",
            "         21.8281, 21.8281, 21.8281, 21.8281, 20.6719, 20.6719, 20.6719, 20.6719],\n",
            "        [29.2812, 29.2812, 29.2812, 29.2812, 17.7344, 17.7344, 17.7344, 17.7344,\n",
            "         18.2812, 18.2812, 18.2812, 18.2812, 18.0938, 18.0938, 18.0938, 18.0938],\n",
            "        [20.8750, 20.8750, 20.8750, 20.8750, 28.7344, 28.7344, 28.7344, 28.7344,\n",
            "         17.5781, 17.5781, 17.5781, 17.5781, 19.0781, 19.0781, 19.0781, 19.0781],\n",
            "        [18.5625, 18.5625, 18.5625, 18.5625, 26.7031, 26.7031, 26.7031, 26.7031,\n",
            "         16.9219, 16.9219, 16.9219, 16.9219, 18.5938, 18.5938, 18.5938, 18.5938],\n",
            "        [18.7031, 18.7031, 18.7031, 18.7031, 27.0156, 27.0156, 27.0156, 27.0156,\n",
            "         17.3594, 17.3594, 17.3594, 17.3594, 18.6250, 18.6250, 18.6250, 18.6250],\n",
            "        [18.8594, 18.8594, 18.8594, 18.8594, 27.9531, 27.9531, 27.9531, 27.9531,\n",
            "         16.7656, 16.7656, 16.7656, 16.7656, 19.8438, 19.8438, 19.8438, 19.8438],\n",
            "        [20.8281, 20.8281, 20.8281, 20.8281, 21.2031, 21.2031, 21.2031, 21.2031,\n",
            "         31.5312, 31.5312, 31.5312, 31.5312, 23.2812, 23.2812, 23.2812, 23.2812],\n",
            "        [18.1719, 18.1719, 18.1719, 18.1719, 19.0781, 19.0781, 19.0781, 19.0781,\n",
            "         32.0000, 32.0000, 32.0000, 32.0000, 23.0469, 23.0469, 23.0469, 23.0469],\n",
            "        [18.0156, 18.0156, 18.0156, 18.0156, 20.3125, 20.3125, 20.3125, 20.3125,\n",
            "         30.0469, 30.0469, 30.0469, 30.0469, 22.4375, 22.4375, 22.4375, 22.4375],\n",
            "        [20.9062, 20.9062, 20.9062, 20.9062, 19.9531, 19.9531, 19.9531, 19.9531,\n",
            "         31.8906, 31.8906, 31.8906, 31.8906, 21.3281, 21.3281, 21.3281, 21.3281],\n",
            "        [21.7031, 21.7031, 21.7031, 21.7031, 19.2812, 19.2812, 19.2812, 19.2812,\n",
            "         23.2031, 23.2031, 23.2031, 23.2031, 27.9062, 27.9062, 27.9062, 27.9062],\n",
            "        [19.5469, 19.5469, 19.5469, 19.5469, 17.3125, 17.3125, 17.3125, 17.3125,\n",
            "         18.7656, 18.7656, 18.7656, 18.7656, 24.1875, 24.1875, 24.1875, 24.1875],\n",
            "        [20.1406, 20.1406, 20.1406, 20.1406, 18.5000, 18.5000, 18.5000, 18.5000,\n",
            "         21.8281, 21.8281, 21.8281, 21.8281, 25.0469, 25.0469, 25.0469, 25.0469],\n",
            "        [22.2812, 22.2812, 22.2812, 22.2812, 20.8594, 20.8594, 20.8594, 20.8594,\n",
            "         22.9375, 22.9375, 22.9375, 22.9375, 28.9375, 28.9375, 28.9375, 28.9375]],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Predicted Labels: tensor([ 0,  0,  0,  0,  4,  4,  4,  4,  8,  8,  8,  8, 12, 12, 12, 12],\n",
            "       device='cuda:0')\n",
            "Actual Labels: tensor([0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3], device='cuda:0')\n",
            "Logits per Image: tensor([[35.9375, 35.9375, 35.9375, 35.9375, 23.0938, 23.0938, 23.0938, 23.0938,\n",
            "         21.3594, 21.3594, 21.3594, 21.3594, 28.3438, 28.3438, 28.3438, 28.3438],\n",
            "        [31.5625, 31.5625, 31.5625, 31.5625, 22.0312, 22.0312, 22.0312, 22.0312,\n",
            "         23.0625, 23.0625, 23.0625, 23.0625, 26.9844, 26.9844, 26.9844, 26.9844],\n",
            "        [36.4375, 36.4375, 36.4375, 36.4375, 21.9375, 21.9375, 21.9375, 21.9375,\n",
            "         25.6406, 25.6406, 25.6406, 25.6406, 29.3125, 29.3125, 29.3125, 29.3125],\n",
            "        [27.8125, 27.8125, 27.8125, 27.8125, 16.7969, 16.7969, 16.7969, 16.7969,\n",
            "         27.5156, 27.5156, 27.5156, 27.5156, 25.5156, 25.5156, 25.5156, 25.5156],\n",
            "        [16.6875, 16.6875, 16.6875, 16.6875, 23.3438, 23.3438, 23.3438, 23.3438,\n",
            "         15.7578, 15.7578, 15.7578, 15.7578, 16.0469, 16.0469, 16.0469, 16.0469],\n",
            "        [19.8281, 19.8281, 19.8281, 19.8281, 31.3594, 31.3594, 31.3594, 31.3594,\n",
            "         18.8594, 18.8594, 18.8594, 18.8594, 13.6406, 13.6406, 13.6406, 13.6406],\n",
            "        [20.3438, 20.3438, 20.3438, 20.3438, 31.4375, 31.4375, 31.4375, 31.4375,\n",
            "         19.4219, 19.4219, 19.4219, 19.4219, 15.2188, 15.2188, 15.2188, 15.2188],\n",
            "        [21.2969, 21.2969, 21.2969, 21.2969, 29.0938, 29.0938, 29.0938, 29.0938,\n",
            "         20.2344, 20.2344, 20.2344, 20.2344, 18.8125, 18.8125, 18.8125, 18.8125],\n",
            "        [22.8125, 22.8125, 22.8125, 22.8125, 17.2812, 17.2812, 17.2812, 17.2812,\n",
            "         30.0938, 30.0938, 30.0938, 30.0938, 19.2656, 19.2656, 19.2656, 19.2656],\n",
            "        [28.7344, 28.7344, 28.7344, 28.7344, 22.8438, 22.8438, 22.8438, 22.8438,\n",
            "         33.2812, 33.2812, 33.2812, 33.2812, 24.2344, 24.2344, 24.2344, 24.2344],\n",
            "        [24.5938, 24.5938, 24.5938, 24.5938, 19.4688, 19.4688, 19.4688, 19.4688,\n",
            "         30.0469, 30.0469, 30.0469, 30.0469, 24.7031, 24.7031, 24.7031, 24.7031],\n",
            "        [27.2812, 27.2812, 27.2812, 27.2812, 19.2969, 19.2969, 19.2969, 19.2969,\n",
            "         27.6406, 27.6406, 27.6406, 27.6406, 26.3125, 26.3125, 26.3125, 26.3125],\n",
            "        [27.9531, 27.9531, 27.9531, 27.9531, 17.6406, 17.6406, 17.6406, 17.6406,\n",
            "         24.8594, 24.8594, 24.8594, 24.8594, 31.0156, 31.0156, 31.0156, 31.0156],\n",
            "        [29.6406, 29.6406, 29.6406, 29.6406, 19.5469, 19.5469, 19.5469, 19.5469,\n",
            "         31.5156, 31.5156, 31.5156, 31.5156, 32.9062, 32.9062, 32.9062, 32.9062],\n",
            "        [25.1562, 25.1562, 25.1562, 25.1562, 18.1562, 18.1562, 18.1562, 18.1562,\n",
            "         25.6719, 25.6719, 25.6719, 25.6719, 32.5312, 32.5312, 32.5312, 32.5312],\n",
            "        [29.8125, 29.8125, 29.8125, 29.8125, 20.0000, 20.0000, 20.0000, 20.0000,\n",
            "         29.5312, 29.5312, 29.5312, 29.5312, 36.4688, 36.4688, 36.4688, 36.4688]],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Predicted Labels: tensor([ 0,  0,  0,  0,  4,  4,  4,  4,  8,  8,  8,  8, 12, 12, 12, 12],\n",
            "       device='cuda:0')\n",
            "Actual Labels: tensor([4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 7], device='cuda:0')\n",
            "Logits per Image: tensor([[32.1250, 32.1250, 32.1250, 32.1250, 23.2344, 23.2344, 23.2344, 23.2344,\n",
            "         20.9844, 20.9844, 20.9844, 20.9844, 16.0625, 16.0625, 16.0625, 16.0625],\n",
            "        [30.3906, 30.3906, 30.3906, 30.3906, 25.0938, 25.0938, 25.0938, 25.0938,\n",
            "         18.3750, 18.3750, 18.3750, 18.3750, 16.0938, 16.0938, 16.0938, 16.0938],\n",
            "        [32.8750, 32.8750, 32.8750, 32.8750, 15.9922, 15.9922, 15.9922, 15.9922,\n",
            "         16.9688, 16.9688, 16.9688, 16.9688, 17.5000, 17.5000, 17.5000, 17.5000],\n",
            "        [32.7500, 32.7500, 32.7500, 32.7500, 22.0312, 22.0312, 22.0312, 22.0312,\n",
            "         17.7031, 17.7031, 17.7031, 17.7031, 15.3828, 15.3828, 15.3828, 15.3828],\n",
            "        [24.1250, 24.1250, 24.1250, 24.1250, 34.1562, 34.1562, 34.1562, 34.1562,\n",
            "         20.2656, 20.2656, 20.2656, 20.2656, 18.5625, 18.5625, 18.5625, 18.5625],\n",
            "        [20.5625, 20.5625, 20.5625, 20.5625, 33.8438, 33.8438, 33.8438, 33.8438,\n",
            "         23.5625, 23.5625, 23.5625, 23.5625, 20.9531, 20.9531, 20.9531, 20.9531],\n",
            "        [22.7812, 22.7812, 22.7812, 22.7812, 33.7188, 33.7188, 33.7188, 33.7188,\n",
            "         17.0000, 17.0000, 17.0000, 17.0000, 19.1406, 19.1406, 19.1406, 19.1406],\n",
            "        [20.3906, 20.3906, 20.3906, 20.3906, 35.4375, 35.4375, 35.4375, 35.4375,\n",
            "         19.6875, 19.6875, 19.6875, 19.6875, 17.1719, 17.1719, 17.1719, 17.1719],\n",
            "        [22.9688, 22.9688, 22.9688, 22.9688, 21.0938, 21.0938, 21.0938, 21.0938,\n",
            "         27.1406, 27.1406, 27.1406, 27.1406, 19.1406, 19.1406, 19.1406, 19.1406],\n",
            "        [19.1875, 19.1875, 19.1875, 19.1875, 23.2969, 23.2969, 23.2969, 23.2969,\n",
            "         31.8438, 31.8438, 31.8438, 31.8438, 15.4141, 15.4141, 15.4141, 15.4141],\n",
            "        [17.6094, 17.6094, 17.6094, 17.6094, 18.0781, 18.0781, 18.0781, 18.0781,\n",
            "         31.1094, 31.1094, 31.1094, 31.1094, 14.7422, 14.7422, 14.7422, 14.7422],\n",
            "        [18.3281, 18.3281, 18.3281, 18.3281, 22.2344, 22.2344, 22.2344, 22.2344,\n",
            "         32.5312, 32.5312, 32.5312, 32.5312, 14.3984, 14.3984, 14.3984, 14.3984],\n",
            "        [16.9062, 16.9062, 16.9062, 16.9062, 16.1406, 16.1406, 16.1406, 16.1406,\n",
            "         18.4062, 18.4062, 18.4062, 18.4062, 27.9062, 27.9062, 27.9062, 27.9062],\n",
            "        [20.4062, 20.4062, 20.4062, 20.4062, 19.9375, 19.9375, 19.9375, 19.9375,\n",
            "         17.5156, 17.5156, 17.5156, 17.5156, 28.5625, 28.5625, 28.5625, 28.5625],\n",
            "        [17.4219, 17.4219, 17.4219, 17.4219, 15.2578, 15.2578, 15.2578, 15.2578,\n",
            "         19.1875, 19.1875, 19.1875, 19.1875, 26.3750, 26.3750, 26.3750, 26.3750],\n",
            "        [17.6875, 17.6875, 17.6875, 17.6875, 20.8594, 20.8594, 20.8594, 20.8594,\n",
            "         21.3438, 21.3438, 21.3438, 21.3438, 27.6719, 27.6719, 27.6719, 27.6719]],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Predicted Labels: tensor([ 0,  0,  0,  0,  4,  4,  4,  4,  8,  8,  8,  8, 12, 12, 12, 12],\n",
            "       device='cuda:0')\n",
            "Actual Labels: tensor([ 8,  8,  8,  8,  9,  9,  9,  9, 10, 10, 10, 10, 11, 11, 11, 11],\n",
            "       device='cuda:0')\n",
            "Logits per Image: tensor([[35.4375, 35.4375, 35.4375, 35.4375, 23.2188, 23.2188, 23.2188, 23.2188,\n",
            "         29.7188, 29.7188, 29.7188, 29.7188, 24.4844, 24.4844, 24.4844, 24.4844],\n",
            "        [35.3438, 35.3438, 35.3438, 35.3438, 21.3594, 21.3594, 21.3594, 21.3594,\n",
            "         30.8906, 30.8906, 30.8906, 30.8906, 23.8281, 23.8281, 23.8281, 23.8281],\n",
            "        [32.4375, 32.4375, 32.4375, 32.4375, 24.2031, 24.2031, 24.2031, 24.2031,\n",
            "         29.4375, 29.4375, 29.4375, 29.4375, 25.7188, 25.7188, 25.7188, 25.7188],\n",
            "        [33.2812, 33.2812, 33.2812, 33.2812, 21.7188, 21.7188, 21.7188, 21.7188,\n",
            "         28.3594, 28.3594, 28.3594, 28.3594, 25.3906, 25.3906, 25.3906, 25.3906],\n",
            "        [23.5625, 23.5625, 23.5625, 23.5625, 37.6875, 37.6875, 37.6875, 37.6875,\n",
            "         25.7812, 25.7812, 25.7812, 25.7812, 20.5938, 20.5938, 20.5938, 20.5938],\n",
            "        [21.9375, 21.9375, 21.9375, 21.9375, 32.4062, 32.4062, 32.4062, 32.4062,\n",
            "         25.8906, 25.8906, 25.8906, 25.8906, 21.5781, 21.5781, 21.5781, 21.5781],\n",
            "        [27.7500, 27.7500, 27.7500, 27.7500, 28.9219, 28.9219, 28.9219, 28.9219,\n",
            "         27.6719, 27.6719, 27.6719, 27.6719, 24.8594, 24.8594, 24.8594, 24.8594],\n",
            "        [22.6094, 22.6094, 22.6094, 22.6094, 37.0312, 37.0312, 37.0312, 37.0312,\n",
            "         26.9531, 26.9531, 26.9531, 26.9531, 21.1719, 21.1719, 21.1719, 21.1719],\n",
            "        [21.6406, 21.6406, 21.6406, 21.6406, 22.2969, 22.2969, 22.2969, 22.2969,\n",
            "         31.5625, 31.5625, 31.5625, 31.5625, 21.5156, 21.5156, 21.5156, 21.5156],\n",
            "        [22.5938, 22.5938, 22.5938, 22.5938, 21.0938, 21.0938, 21.0938, 21.0938,\n",
            "         25.5000, 25.5000, 25.5000, 25.5000, 21.2812, 21.2812, 21.2812, 21.2812],\n",
            "        [24.3906, 24.3906, 24.3906, 24.3906, 24.9531, 24.9531, 24.9531, 24.9531,\n",
            "         30.9219, 30.9219, 30.9219, 30.9219, 25.9688, 25.9688, 25.9688, 25.9688],\n",
            "        [25.2969, 25.2969, 25.2969, 25.2969, 21.6562, 21.6562, 21.6562, 21.6562,\n",
            "         29.9219, 29.9219, 29.9219, 29.9219, 23.7969, 23.7969, 23.7969, 23.7969],\n",
            "        [27.9688, 27.9688, 27.9688, 27.9688, 21.8281, 21.8281, 21.8281, 21.8281,\n",
            "         23.1406, 23.1406, 23.1406, 23.1406, 31.7969, 31.7969, 31.7969, 31.7969],\n",
            "        [28.7344, 28.7344, 28.7344, 28.7344, 24.0781, 24.0781, 24.0781, 24.0781,\n",
            "         25.1719, 25.1719, 25.1719, 25.1719, 34.0000, 34.0000, 34.0000, 34.0000],\n",
            "        [26.4062, 26.4062, 26.4062, 26.4062, 26.4844, 26.4844, 26.4844, 26.4844,\n",
            "         24.0469, 24.0469, 24.0469, 24.0469, 27.3906, 27.3906, 27.3906, 27.3906],\n",
            "        [27.5625, 27.5625, 27.5625, 27.5625, 23.5625, 23.5625, 23.5625, 23.5625,\n",
            "         26.0938, 26.0938, 26.0938, 26.0938, 31.8750, 31.8750, 31.8750, 31.8750]],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Predicted Labels: tensor([ 0,  0,  0,  0,  4,  4,  4,  4,  8,  8,  8,  8, 12, 12, 12, 12],\n",
            "       device='cuda:0')\n",
            "Actual Labels: tensor([12, 12, 12, 12, 13, 13, 13, 13, 14, 14, 14, 14, 15, 15, 15, 15],\n",
            "       device='cuda:0')\n",
            "Logits per Image: tensor([[31.0000, 31.0000, 31.0000, 31.0000, 25.2344, 25.2344, 25.2344, 25.2344,\n",
            "         22.7188, 22.7188, 22.7188, 22.7188, 24.7500, 24.7500, 24.7500, 24.7500],\n",
            "        [26.0469, 26.0469, 26.0469, 26.0469, 20.3906, 20.3906, 20.3906, 20.3906,\n",
            "         19.9062, 19.9062, 19.9062, 19.9062, 20.5312, 20.5312, 20.5312, 20.5312],\n",
            "        [32.2188, 32.2188, 32.2188, 32.2188, 23.0781, 23.0781, 23.0781, 23.0781,\n",
            "         26.1719, 26.1719, 26.1719, 26.1719, 20.6875, 20.6875, 20.6875, 20.6875],\n",
            "        [28.7812, 28.7812, 28.7812, 28.7812, 27.1875, 27.1875, 27.1875, 27.1875,\n",
            "         25.3750, 25.3750, 25.3750, 25.3750, 18.5938, 18.5938, 18.5938, 18.5938],\n",
            "        [25.0312, 25.0312, 25.0312, 25.0312, 32.1875, 32.1875, 32.1875, 32.1875,\n",
            "         25.5312, 25.5312, 25.5312, 25.5312, 24.3125, 24.3125, 24.3125, 24.3125],\n",
            "        [28.6406, 28.6406, 28.6406, 28.6406, 37.5625, 37.5625, 37.5625, 37.5625,\n",
            "         25.8281, 25.8281, 25.8281, 25.8281, 23.0938, 23.0938, 23.0938, 23.0938],\n",
            "        [22.7031, 22.7031, 22.7031, 22.7031, 27.7188, 27.7188, 27.7188, 27.7188,\n",
            "         21.9219, 21.9219, 21.9219, 21.9219, 18.1250, 18.1250, 18.1250, 18.1250],\n",
            "        [25.3906, 25.3906, 25.3906, 25.3906, 29.7188, 29.7188, 29.7188, 29.7188,\n",
            "         22.6719, 22.6719, 22.6719, 22.6719, 25.9531, 25.9531, 25.9531, 25.9531],\n",
            "        [25.0312, 25.0312, 25.0312, 25.0312, 19.8750, 19.8750, 19.8750, 19.8750,\n",
            "         34.5312, 34.5312, 34.5312, 34.5312, 22.4219, 22.4219, 22.4219, 22.4219],\n",
            "        [23.2031, 23.2031, 23.2031, 23.2031, 19.2500, 19.2500, 19.2500, 19.2500,\n",
            "         33.2812, 33.2812, 33.2812, 33.2812, 20.3125, 20.3125, 20.3125, 20.3125],\n",
            "        [22.8906, 22.8906, 22.8906, 22.8906, 18.2969, 18.2969, 18.2969, 18.2969,\n",
            "         30.5312, 30.5312, 30.5312, 30.5312, 19.8438, 19.8438, 19.8438, 19.8438],\n",
            "        [22.0312, 22.0312, 22.0312, 22.0312, 18.0625, 18.0625, 18.0625, 18.0625,\n",
            "         34.0000, 34.0000, 34.0000, 34.0000, 18.8594, 18.8594, 18.8594, 18.8594],\n",
            "        [21.2188, 21.2188, 21.2188, 21.2188, 21.5781, 21.5781, 21.5781, 21.5781,\n",
            "         18.5781, 18.5781, 18.5781, 18.5781, 28.8594, 28.8594, 28.8594, 28.8594],\n",
            "        [20.4688, 20.4688, 20.4688, 20.4688, 23.2188, 23.2188, 23.2188, 23.2188,\n",
            "         16.2812, 16.2812, 16.2812, 16.2812, 27.0000, 27.0000, 27.0000, 27.0000],\n",
            "        [21.9062, 21.9062, 21.9062, 21.9062, 22.3438, 22.3438, 22.3438, 22.3438,\n",
            "         17.5312, 17.5312, 17.5312, 17.5312, 28.3125, 28.3125, 28.3125, 28.3125],\n",
            "        [21.0938, 21.0938, 21.0938, 21.0938, 24.4062, 24.4062, 24.4062, 24.4062,\n",
            "         18.3594, 18.3594, 18.3594, 18.3594, 29.3594, 29.3594, 29.3594, 29.3594]],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Predicted Labels: tensor([ 0,  0,  0,  0,  4,  4,  4,  4,  8,  8,  8,  8, 12, 12, 12, 12],\n",
            "       device='cuda:0')\n",
            "Actual Labels: tensor([16, 16, 16, 16, 17, 17, 17, 17, 18, 18, 18, 18, 19, 19, 19, 19],\n",
            "       device='cuda:0')\n",
            "Logits per Image: tensor([[28.2969, 28.2969, 28.2969, 28.2969, 22.1094, 22.1094, 22.1094, 22.1094,\n",
            "         18.8438, 18.8438, 18.8438, 18.8438, 20.0469, 20.0469, 20.0469, 20.0469],\n",
            "        [29.2188, 29.2188, 29.2188, 29.2188, 23.4844, 23.4844, 23.4844, 23.4844,\n",
            "         24.0156, 24.0156, 24.0156, 24.0156, 22.5625, 22.5625, 22.5625, 22.5625],\n",
            "        [26.4062, 26.4062, 26.4062, 26.4062, 19.4531, 19.4531, 19.4531, 19.4531,\n",
            "         19.9375, 19.9375, 19.9375, 19.9375, 21.6719, 21.6719, 21.6719, 21.6719],\n",
            "        [27.7812, 27.7812, 27.7812, 27.7812, 25.9844, 25.9844, 25.9844, 25.9844,\n",
            "         22.7812, 22.7812, 22.7812, 22.7812, 20.9375, 20.9375, 20.9375, 20.9375],\n",
            "        [22.4688, 22.4688, 22.4688, 22.4688, 28.7188, 28.7188, 28.7188, 28.7188,\n",
            "         20.9375, 20.9375, 20.9375, 20.9375, 20.9062, 20.9062, 20.9062, 20.9062],\n",
            "        [17.8438, 17.8438, 17.8438, 17.8438, 30.5625, 30.5625, 30.5625, 30.5625,\n",
            "         18.7188, 18.7188, 18.7188, 18.7188, 20.2344, 20.2344, 20.2344, 20.2344],\n",
            "        [18.4062, 18.4062, 18.4062, 18.4062, 28.9531, 28.9531, 28.9531, 28.9531,\n",
            "         21.7812, 21.7812, 21.7812, 21.7812, 21.2969, 21.2969, 21.2969, 21.2969],\n",
            "        [19.8438, 19.8438, 19.8438, 19.8438, 27.1094, 27.1094, 27.1094, 27.1094,\n",
            "         19.1094, 19.1094, 19.1094, 19.1094, 20.7188, 20.7188, 20.7188, 20.7188],\n",
            "        [21.6875, 21.6875, 21.6875, 21.6875, 21.1719, 21.1719, 21.1719, 21.1719,\n",
            "         27.6250, 27.6250, 27.6250, 27.6250, 21.3125, 21.3125, 21.3125, 21.3125],\n",
            "        [25.8750, 25.8750, 25.8750, 25.8750, 22.8438, 22.8438, 22.8438, 22.8438,\n",
            "         32.5312, 32.5312, 32.5312, 32.5312, 23.7812, 23.7812, 23.7812, 23.7812],\n",
            "        [23.7344, 23.7344, 23.7344, 23.7344, 20.1094, 20.1094, 20.1094, 20.1094,\n",
            "         29.9062, 29.9062, 29.9062, 29.9062, 22.5938, 22.5938, 22.5938, 22.5938],\n",
            "        [21.1094, 21.1094, 21.1094, 21.1094, 19.3750, 19.3750, 19.3750, 19.3750,\n",
            "         29.1094, 29.1094, 29.1094, 29.1094, 21.8281, 21.8281, 21.8281, 21.8281],\n",
            "        [21.2969, 21.2969, 21.2969, 21.2969, 21.7031, 21.7031, 21.7031, 21.7031,\n",
            "         21.2812, 21.2812, 21.2812, 21.2812, 26.1562, 26.1562, 26.1562, 26.1562],\n",
            "        [20.2656, 20.2656, 20.2656, 20.2656, 19.5000, 19.5000, 19.5000, 19.5000,\n",
            "         20.1406, 20.1406, 20.1406, 20.1406, 24.5312, 24.5312, 24.5312, 24.5312],\n",
            "        [24.7188, 24.7188, 24.7188, 24.7188, 22.0781, 22.0781, 22.0781, 22.0781,\n",
            "         21.6250, 21.6250, 21.6250, 21.6250, 26.4688, 26.4688, 26.4688, 26.4688],\n",
            "        [23.5312, 23.5312, 23.5312, 23.5312, 22.2969, 22.2969, 22.2969, 22.2969,\n",
            "         24.8906, 24.8906, 24.8906, 24.8906, 28.9219, 28.9219, 28.9219, 28.9219]],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Predicted Labels: tensor([ 0,  0,  0,  0,  4,  4,  4,  4,  8,  8,  8,  8, 12, 12, 12, 12],\n",
            "       device='cuda:0')\n",
            "Actual Labels: tensor([20, 20, 20, 20, 21, 21, 21, 21, 22, 22, 22, 22, 23, 23, 23, 23],\n",
            "       device='cuda:0')\n",
            "Logits per Image: tensor([[32.0625, 32.0625, 32.0625, 32.0625, 24.2656, 24.2656, 24.2656, 24.2656,\n",
            "         19.2969, 19.2969, 19.2969, 19.2969, 28.4844, 28.4844, 28.4844, 28.4844],\n",
            "        [33.3438, 33.3438, 33.3438, 33.3438, 23.5156, 23.5156, 23.5156, 23.5156,\n",
            "         20.2969, 20.2969, 20.2969, 20.2969, 26.6406, 26.6406, 26.6406, 26.6406],\n",
            "        [33.9062, 33.9062, 33.9062, 33.9062, 24.0312, 24.0312, 24.0312, 24.0312,\n",
            "         21.2188, 21.2188, 21.2188, 21.2188, 26.1875, 26.1875, 26.1875, 26.1875],\n",
            "        [30.3281, 30.3281, 30.3281, 30.3281, 23.0938, 23.0938, 23.0938, 23.0938,\n",
            "         21.8906, 21.8906, 21.8906, 21.8906, 26.7031, 26.7031, 26.7031, 26.7031],\n",
            "        [20.3750, 20.3750, 20.3750, 20.3750, 29.4062, 29.4062, 29.4062, 29.4062,\n",
            "         19.7969, 19.7969, 19.7969, 19.7969, 19.0312, 19.0312, 19.0312, 19.0312],\n",
            "        [19.2656, 19.2656, 19.2656, 19.2656, 28.6406, 28.6406, 28.6406, 28.6406,\n",
            "         19.8906, 19.8906, 19.8906, 19.8906, 17.2969, 17.2969, 17.2969, 17.2969],\n",
            "        [20.9531, 20.9531, 20.9531, 20.9531, 26.2344, 26.2344, 26.2344, 26.2344,\n",
            "         22.3281, 22.3281, 22.3281, 22.3281, 25.4375, 25.4375, 25.4375, 25.4375],\n",
            "        [19.2969, 19.2969, 19.2969, 19.2969, 29.5625, 29.5625, 29.5625, 29.5625,\n",
            "         20.6719, 20.6719, 20.6719, 20.6719, 19.6719, 19.6719, 19.6719, 19.6719],\n",
            "        [18.6250, 18.6250, 18.6250, 18.6250, 19.8281, 19.8281, 19.8281, 19.8281,\n",
            "         27.6250, 27.6250, 27.6250, 27.6250, 17.5781, 17.5781, 17.5781, 17.5781],\n",
            "        [15.5156, 15.5156, 15.5156, 15.5156, 18.6406, 18.6406, 18.6406, 18.6406,\n",
            "         27.9062, 27.9062, 27.9062, 27.9062, 15.9844, 15.9844, 15.9844, 15.9844],\n",
            "        [23.8438, 23.8438, 23.8438, 23.8438, 22.9531, 22.9531, 22.9531, 22.9531,\n",
            "         31.4844, 31.4844, 31.4844, 31.4844, 23.9375, 23.9375, 23.9375, 23.9375],\n",
            "        [17.7031, 17.7031, 17.7031, 17.7031, 22.0000, 22.0000, 22.0000, 22.0000,\n",
            "         29.1562, 29.1562, 29.1562, 29.1562, 17.7812, 17.7812, 17.7812, 17.7812],\n",
            "        [21.8125, 21.8125, 21.8125, 21.8125, 18.6250, 18.6250, 18.6250, 18.6250,\n",
            "         21.0625, 21.0625, 21.0625, 21.0625, 28.8281, 28.8281, 28.8281, 28.8281],\n",
            "        [21.2500, 21.2500, 21.2500, 21.2500, 21.5469, 21.5469, 21.5469, 21.5469,\n",
            "         19.8125, 19.8125, 19.8125, 19.8125, 26.1719, 26.1719, 26.1719, 26.1719],\n",
            "        [24.7656, 24.7656, 24.7656, 24.7656, 20.3594, 20.3594, 20.3594, 20.3594,\n",
            "         18.3750, 18.3750, 18.3750, 18.3750, 30.2188, 30.2188, 30.2188, 30.2188],\n",
            "        [15.3359, 15.3359, 15.3359, 15.3359, 14.1875, 14.1875, 14.1875, 14.1875,\n",
            "         12.5234, 12.5234, 12.5234, 12.5234, 30.5312, 30.5312, 30.5312, 30.5312]],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Predicted Labels: tensor([ 0,  0,  0,  0,  4,  4,  4,  4,  8,  8,  8,  8, 12, 12, 12, 12],\n",
            "       device='cuda:0')\n",
            "Actual Labels: tensor([24, 24, 24, 24, 25, 25, 25, 25, 26, 26, 26, 26, 27, 27, 27, 27],\n",
            "       device='cuda:0')\n",
            "Logits per Image: tensor([[33.1562, 33.1562, 33.1562, 33.1562, 20.9219, 20.9219, 20.9219, 20.9219,\n",
            "         22.2188, 22.2188, 22.2188, 22.2188, 23.2344, 23.2344, 23.2344, 23.2344],\n",
            "        [32.3438, 32.3438, 32.3438, 32.3438, 23.0938, 23.0938, 23.0938, 23.0938,\n",
            "         21.9375, 21.9375, 21.9375, 21.9375, 22.3125, 22.3125, 22.3125, 22.3125],\n",
            "        [28.9688, 28.9688, 28.9688, 28.9688, 21.2344, 21.2344, 21.2344, 21.2344,\n",
            "         21.0156, 21.0156, 21.0156, 21.0156, 19.6406, 19.6406, 19.6406, 19.6406],\n",
            "        [29.5469, 29.5469, 29.5469, 29.5469, 18.1250, 18.1250, 18.1250, 18.1250,\n",
            "         17.7656, 17.7656, 17.7656, 17.7656, 20.9375, 20.9375, 20.9375, 20.9375],\n",
            "        [23.1875, 23.1875, 23.1875, 23.1875, 27.7656, 27.7656, 27.7656, 27.7656,\n",
            "         19.9375, 19.9375, 19.9375, 19.9375, 19.4844, 19.4844, 19.4844, 19.4844],\n",
            "        [21.8281, 21.8281, 21.8281, 21.8281, 29.0625, 29.0625, 29.0625, 29.0625,\n",
            "         18.8438, 18.8438, 18.8438, 18.8438, 15.6484, 15.6484, 15.6484, 15.6484],\n",
            "        [22.8906, 22.8906, 22.8906, 22.8906, 31.5156, 31.5156, 31.5156, 31.5156,\n",
            "         19.4062, 19.4062, 19.4062, 19.4062, 19.3281, 19.3281, 19.3281, 19.3281],\n",
            "        [22.6875, 22.6875, 22.6875, 22.6875, 31.6094, 31.6094, 31.6094, 31.6094,\n",
            "         19.8281, 19.8281, 19.8281, 19.8281, 17.6250, 17.6250, 17.6250, 17.6250],\n",
            "        [23.0000, 23.0000, 23.0000, 23.0000, 20.1250, 20.1250, 20.1250, 20.1250,\n",
            "         28.0469, 28.0469, 28.0469, 28.0469, 19.7188, 19.7188, 19.7188, 19.7188],\n",
            "        [22.2344, 22.2344, 22.2344, 22.2344, 18.5781, 18.5781, 18.5781, 18.5781,\n",
            "         27.7344, 27.7344, 27.7344, 27.7344, 20.5938, 20.5938, 20.5938, 20.5938],\n",
            "        [19.6406, 19.6406, 19.6406, 19.6406, 19.5000, 19.5000, 19.5000, 19.5000,\n",
            "         28.9844, 28.9844, 28.9844, 28.9844, 17.7344, 17.7344, 17.7344, 17.7344],\n",
            "        [17.5781, 17.5781, 17.5781, 17.5781, 19.1250, 19.1250, 19.1250, 19.1250,\n",
            "         28.4688, 28.4688, 28.4688, 28.4688, 16.8438, 16.8438, 16.8438, 16.8438],\n",
            "        [22.5625, 22.5625, 22.5625, 22.5625, 21.7812, 21.7812, 21.7812, 21.7812,\n",
            "         19.6562, 19.6562, 19.6562, 19.6562, 28.4688, 28.4688, 28.4688, 28.4688],\n",
            "        [25.1094, 25.1094, 25.1094, 25.1094, 20.6250, 20.6250, 20.6250, 20.6250,\n",
            "         21.4062, 21.4062, 21.4062, 21.4062, 37.2812, 37.2812, 37.2812, 37.2812],\n",
            "        [26.8750, 26.8750, 26.8750, 26.8750, 21.3594, 21.3594, 21.3594, 21.3594,\n",
            "         22.2344, 22.2344, 22.2344, 22.2344, 30.0781, 30.0781, 30.0781, 30.0781],\n",
            "        [27.3906, 27.3906, 27.3906, 27.3906, 17.5781, 17.5781, 17.5781, 17.5781,\n",
            "         19.6875, 19.6875, 19.6875, 19.6875, 35.1562, 35.1562, 35.1562, 35.1562]],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Predicted Labels: tensor([ 0,  0,  0,  0,  4,  4,  4,  4,  8,  8,  8,  8, 12, 12, 12, 12],\n",
            "       device='cuda:0')\n",
            "Actual Labels: tensor([28, 28, 28, 28, 29, 29, 29, 29, 30, 30, 30, 30, 31, 31, 31, 31],\n",
            "       device='cuda:0')\n",
            "Logits per Image: tensor([[32.0938, 32.0938, 32.0938, 32.0938],\n",
            "        [32.5938, 32.5938, 32.5938, 32.5938],\n",
            "        [34.1250, 34.1250, 34.1250, 34.1250],\n",
            "        [30.6875, 30.6875, 30.6875, 30.6875]], device='cuda:0',\n",
            "       dtype=torch.float16)\n",
            "Predicted Labels: tensor([0, 0, 0, 0], device='cuda:0')\n",
            "Actual Labels: tensor([32, 32, 32, 32], device='cuda:0')\n",
            "Validation Top-1 Acc: 3.03%, Validation Top-3 Acc: 9.09%\n",
            "Epoch: 3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/9 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "440c1a051379499ca98cc8507837aa60"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-76-b415bed4dfe9>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mtrain_total\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_correct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_top1_correct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_top3_correct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mpbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0mit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1183\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-70-eb514e485d19>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_paths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_descriptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mPIL\u001b[0m \u001b[0mImage\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRescaled\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m         \"\"\"\n\u001b[0;32m--> 361\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mantialias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation, max_size, antialias)\u001b[0m\n\u001b[1;32m    488\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Anti-alias option is always applied for PIL Image input. Argument antialias is ignored.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         \u001b[0mpil_interpolation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_modes_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF_pil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpil_interpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mF_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mantialias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mantialias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/_functional_pil.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Got inappropriate size arg: {size}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   2190\u001b[0m                 )\n\u001b[1;32m   2191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2192\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2194\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hcveGi9uSziV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a94e9896-f2eb-4a61-c017-ece4c283279d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/Study/DL_CLIP/model/CLIP_4shot_v4.pth'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "torch.save(model.state_dict(), 'CLIP_4shot_v4.pth')\n",
        "shutil.copy('CLIP_4shot_v4.pth', '/content/drive/MyDrive/Study/DL_CLIP/model/CLIP_4shot_v4.pth')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model, preprocess = clip.load(\"ViT-B/32\", device=device, jit=False)\n",
        "loaded_model = loaded_model.to(torch.float32)\n",
        "loaded_model.load_state_dict(torch.load('/content/drive/MyDrive/Study/DL_CLIP/model/CLIP_4shot_v3.pth'))\n",
        "loaded_model.to(device)"
      ],
      "metadata": {
        "id": "mvh6K83kbxl5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e371f261-5af6-4813-f9e0-7c45828777ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CLIP(\n",
              "  (visual): VisionTransformer(\n",
              "    (conv1): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32), bias=False)\n",
              "    (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    (transformer): Transformer(\n",
              "      (resblocks): Sequential(\n",
              "        (0): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (1): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (2): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (3): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (4): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (5): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (6): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (7): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (8): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (9): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (10): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (11): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (transformer): Transformer(\n",
              "    (resblocks): Sequential(\n",
              "      (0): ResidualAttentionBlock(\n",
              "        (attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): Sequential(\n",
              "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (gelu): QuickGELU()\n",
              "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        )\n",
              "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (1): ResidualAttentionBlock(\n",
              "        (attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): Sequential(\n",
              "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (gelu): QuickGELU()\n",
              "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        )\n",
              "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (2): ResidualAttentionBlock(\n",
              "        (attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): Sequential(\n",
              "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (gelu): QuickGELU()\n",
              "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        )\n",
              "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (3): ResidualAttentionBlock(\n",
              "        (attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): Sequential(\n",
              "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (gelu): QuickGELU()\n",
              "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        )\n",
              "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (4): ResidualAttentionBlock(\n",
              "        (attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): Sequential(\n",
              "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (gelu): QuickGELU()\n",
              "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        )\n",
              "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (5): ResidualAttentionBlock(\n",
              "        (attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): Sequential(\n",
              "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (gelu): QuickGELU()\n",
              "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        )\n",
              "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (6): ResidualAttentionBlock(\n",
              "        (attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): Sequential(\n",
              "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (gelu): QuickGELU()\n",
              "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        )\n",
              "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (7): ResidualAttentionBlock(\n",
              "        (attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): Sequential(\n",
              "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (gelu): QuickGELU()\n",
              "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        )\n",
              "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (8): ResidualAttentionBlock(\n",
              "        (attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): Sequential(\n",
              "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (gelu): QuickGELU()\n",
              "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        )\n",
              "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (9): ResidualAttentionBlock(\n",
              "        (attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): Sequential(\n",
              "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (gelu): QuickGELU()\n",
              "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        )\n",
              "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (10): ResidualAttentionBlock(\n",
              "        (attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): Sequential(\n",
              "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (gelu): QuickGELU()\n",
              "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        )\n",
              "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (11): ResidualAttentionBlock(\n",
              "        (attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): Sequential(\n",
              "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (gelu): QuickGELU()\n",
              "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        )\n",
              "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (token_embedding): Embedding(49408, 512)\n",
              "  (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5ZKxdc_Y7wp",
        "outputId": "89f094cb-1fb5-4fc7-ab69-8152abe1e6b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.2.0-py3-none-any.whl (805 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m805.2/805.2 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.23.5)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.1.0+cu118)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.10.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (23.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (67.7.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n",
            "Installing collected packages: lightning-utilities, torchmetrics\n",
            "Successfully installed lightning-utilities-0.10.0 torchmetrics-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "# 모델을 평가하기 전에 모델을 evaluation 모드로 설정\n",
        "model.eval()\n",
        "\n",
        "# 테스트 루프\n",
        "test_correct = 0\n",
        "test_total = 0\n",
        "true_labels = []\n",
        "predicted_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in testloader:\n",
        "        images, texts, labels_tuple = batch\n",
        "        texts = texts.squeeze(1)\n",
        "        images = images.to(device)\n",
        "        texts = texts.to(device)\n",
        "        labels = labels_tuple[1].to(device)  # 레이블을 적절히 추출\n",
        "\n",
        "        logits_per_image, _ = model(images, texts)\n",
        "\n",
        "        # 예측값과 실제 레이블 저장\n",
        "        _, predicted = logits_per_image.max(1)\n",
        "        true_labels.extend(labels.cpu().numpy())\n",
        "        predicted_labels.extend(predicted.cpu().numpy())\n",
        "\n",
        "        # 정확도 계산\n",
        "        test_correct += (predicted == labels).sum().item()\n",
        "        test_total += labels.size(0)\n",
        "\n",
        "# 전체 테스트 세트에 대한 정확도 출력\n",
        "test_accuracy = 100 * test_correct / test_total\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
        "\n",
        "# Precision, Recall, F1-score 계산\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predicted_labels, average='weighted')\n",
        "\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-score: {f1:.4f}\")\n"
      ],
      "metadata": {
        "id": "wTF5QnZBXMW4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "849b9db8-f48e-47b2-b8f8-c7b927396484"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 3.03%\n",
            "Precision: 0.0061\n",
            "Recall: 0.0303\n",
            "F1-score: 0.0101\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RcMpbxqU3KXH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d42cb5cb9db240658a05bd0f7cc84ef9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7fe6bfb0df3945c9a4c87d12d13b1ca2",
              "IPY_MODEL_e582a7ce0a14452088f99b180139a014",
              "IPY_MODEL_aa894db688dd436a99a986b7ad69e04e"
            ],
            "layout": "IPY_MODEL_8020eaaaf1fc47f9bd2fa971ed8d54a1"
          }
        },
        "7fe6bfb0df3945c9a4c87d12d13b1ca2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5faafd87afac4a25b3df1620cc34f094",
            "placeholder": "​",
            "style": "IPY_MODEL_802d021eb2c648ce9bbe05e652ad14a3",
            "value": "Epoch 1/10, Loss: 0.0612, Train Top-1 Acc: 78.03%, Train Top-3 Acc: 96.97%: 100%"
          }
        },
        "e582a7ce0a14452088f99b180139a014": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9531d70d6b37474ab257a9835aa38914",
            "max": 9,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eee12b3b48214552a506212e804e1985",
            "value": 9
          }
        },
        "aa894db688dd436a99a986b7ad69e04e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66e19f51b16646aabe24f3c826c97832",
            "placeholder": "​",
            "style": "IPY_MODEL_79786d3cb9e74b59806a8516643f295b",
            "value": " 9/9 [00:03&lt;00:00,  3.67it/s]"
          }
        },
        "8020eaaaf1fc47f9bd2fa971ed8d54a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5faafd87afac4a25b3df1620cc34f094": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "802d021eb2c648ce9bbe05e652ad14a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9531d70d6b37474ab257a9835aa38914": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eee12b3b48214552a506212e804e1985": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "66e19f51b16646aabe24f3c826c97832": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79786d3cb9e74b59806a8516643f295b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e07fa7f840c7486991b871b3f8837462": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f03205fc071842e797db837589dbbbba",
              "IPY_MODEL_94e76d4f30784e6e95ecb2ad28745ee1",
              "IPY_MODEL_ea57c7d1ea1341a28257dafd1e2edd4b"
            ],
            "layout": "IPY_MODEL_0bbdc83d51b748ae8fc839f23a7f06a5"
          }
        },
        "f03205fc071842e797db837589dbbbba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_945976db55b2433da5d90add39be8603",
            "placeholder": "​",
            "style": "IPY_MODEL_473a896388af472a915d88eecf920b31",
            "value": "Epoch 2/10, Loss: 0.0014, Train Top-1 Acc: 78.03%, Train Top-3 Acc: 96.97%: 100%"
          }
        },
        "94e76d4f30784e6e95ecb2ad28745ee1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_acaf88d4f79a462aaf0f287a760c80c5",
            "max": 9,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ba79dcbf105d40d3a8b06908fad0086e",
            "value": 9
          }
        },
        "ea57c7d1ea1341a28257dafd1e2edd4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_063540b3ebaa49f49b0efb9b0774b480",
            "placeholder": "​",
            "style": "IPY_MODEL_1d5b4e079bcd4119b092d0119d9a9cf9",
            "value": " 9/9 [00:02&lt;00:00,  3.24it/s]"
          }
        },
        "0bbdc83d51b748ae8fc839f23a7f06a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "945976db55b2433da5d90add39be8603": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "473a896388af472a915d88eecf920b31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "acaf88d4f79a462aaf0f287a760c80c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba79dcbf105d40d3a8b06908fad0086e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "063540b3ebaa49f49b0efb9b0774b480": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d5b4e079bcd4119b092d0119d9a9cf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "440c1a051379499ca98cc8507837aa60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0921f0f6e9ac4f08b6dd89d8f15247f6",
              "IPY_MODEL_bf76884145b642bb828332098f21dde4",
              "IPY_MODEL_75ed55bf793b47f3a7357f4af4eb267e"
            ],
            "layout": "IPY_MODEL_9b8e8e46603c4477a2a88856bc3a977b"
          }
        },
        "0921f0f6e9ac4f08b6dd89d8f15247f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e531639221a94d7ab280f37fc9941f14",
            "placeholder": "​",
            "style": "IPY_MODEL_bed25b6985964f00a23631554b0a2f49",
            "value": "Epoch 3/10, Loss: 0.3989, Train Top-1 Acc: 78.12%, Train Top-3 Acc: 96.88%:  22%"
          }
        },
        "bf76884145b642bb828332098f21dde4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a24dbb20e656407ba2e4041bd2afac9e",
            "max": 9,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f6144c9c5afc4ff792acb5875e0937c7",
            "value": 2
          }
        },
        "75ed55bf793b47f3a7357f4af4eb267e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d576918a57bc4d9d8ff66a94873ba1f1",
            "placeholder": "​",
            "style": "IPY_MODEL_c956b908f90846a7815f3f2d4588b157",
            "value": " 2/9 [00:00&lt;00:02,  2.37it/s]"
          }
        },
        "9b8e8e46603c4477a2a88856bc3a977b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e531639221a94d7ab280f37fc9941f14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bed25b6985964f00a23631554b0a2f49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a24dbb20e656407ba2e4041bd2afac9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6144c9c5afc4ff792acb5875e0937c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d576918a57bc4d9d8ff66a94873ba1f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c956b908f90846a7815f3f2d4588b157": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}